\relax 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Exploring your data}{5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Types of variables}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Continuous, ordinal, and categorical variables}{5}}
\@writefile{toc}{\contentsline {subsubsection}{Exercises}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Qualitative and quantitative treatment of variables in data analysis}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Dependent and independent variables}{7}}
\@writefile{toc}{\contentsline {subsubsection}{Exercises}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Distributions}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces A frequency distribution}}{8}}
\newlabel{fig:distr_1}{{1.1}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces A histogram}}{9}}
\newlabel{fig:distr_2}{{1.2}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces A histogram}}{9}}
\newlabel{fig:distr_3}{{1.3}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Mean, median and mode}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}The mean}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}The median}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}The mode}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Variance}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Sum of squares}{11}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Linear modelling: introduction}{14}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Linear equations}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Straight line with intercept 0 and slope 2}}{15}}
\newlabel{fig:lm_1}{{2.1}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Straight line with intercept -2 and slope 0.5}}{16}}
\newlabel{fig:lm_2}{{2.2}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Exercises}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Straight line with intercept -2 and slope 0.5}}{17}}
\newlabel{fig:lm_3}{{2.3}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Straight line example}}{17}}
\newlabel{fig:lm_4}{{2.4}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Straight line example}}{18}}
\newlabel{fig:lm_5}{{2.5}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Straight line example}}{18}}
\newlabel{fig:lm_6}{{2.6}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Straight line with based on y=1-2x}}{19}}
\newlabel{fig:lm_7}{{2.7}{19}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Linear regression}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Data on holiday spending}}{20}}
\newlabel{fig:lm_8}{{2.8}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Data on holiday spending with an added straight line}}{20}}
\newlabel{fig:lm_9}{{2.9}{20}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Residuals}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Data on variables x and y with an added straight line}}{22}}
\newlabel{fig:lm_10}{{2.10}{22}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Least squares regression lines}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Histogram of the residuals (errors)}}{23}}
\newlabel{fig:lm_11}{{2.11}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Data on variables x and y with an added straight line}}{24}}
\newlabel{fig:lm_12}{{2.12}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Exercises}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Three times the same data set, but with different regression lines}}{25}}
\newlabel{fig:lm_13}{{2.13}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Histogram of the residuals (errors) for three different regression lines, and the respective sums of squared residuals (SSR)}}{25}}
\newlabel{fig:lm_14}{{2.14}{25}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Home prices.}}{26}}
\newlabel{tab:lm_15}{{2.1}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Plot of housing data}}{26}}
\newlabel{fig:lm_16}{{2.15}{26}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Home prices.}}{27}}
\newlabel{tab:lm_17}{{2.2}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces Plot of housing data}}{27}}
\newlabel{fig:lm_18}{{2.16}{27}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Pearson correlation}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces Plot of housing data}}{28}}
\newlabel{fig:lm_19}{{2.17}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.18}{\ignorespaces Plot of housing data}}{29}}
\newlabel{fig:lm_20}{{2.18}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Covariance}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Exercises}{30}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Regression using SPSS}{31}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Linear models}{31}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Inference I: random samples, standard errors and confidence intervals}{33}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The relationship between temperature and volume in a sample of 200 bottles}}{34}}
\newlabel{fig:inf_0}{{3.1}{34}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Population data and sample data}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The relationship between temperature and volume in all 80,000 bottles}}{35}}
\newlabel{fig:inf_1}{{3.2}{35}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Random sampling and the standard error}{35}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Distribution of the 100 sample intercepts and 100 sample slope}}{36}}
\newlabel{fig:inf_3}{{3.3}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Distribution of 1000 sample slopes}}{37}}
\newlabel{fig:inf_5}{{3.4}{37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Standard error and sample size}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Distribution of the sample slope when sample size is 2 (left panel) and when sample size is 20 (right panel)}}{38}}
\newlabel{fig:inf_7}{{3.5}{38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}From sample slope to population slope}{38}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}$t$-distributions}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Difference in the shapes of a normal distribution and a t-distribution}}{40}}
\newlabel{fig:inf_8}{{3.6}{40}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}$T$-statistics}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces The shape of the distribution of sample slopes depends on sample size}}{41}}
\newlabel{fig:inf_9}{{3.7}{41}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces The standard normal distribution and the probability of a Z-score lower than -1.06}}{42}}
\newlabel{fig:inf_9b}{{3.8}{42}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Hypothetical population slopes}{43}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Confidence intervals for smaller sample sizes}{44}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Quantiles for the standard normal and several t-distributions.}}{45}}
\newlabel{tab:nonparmixed_4}{{3.1}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Two t-distributions when sample size is 4 or 200, with corresponding 95 percent intervals}}{46}}
\newlabel{fig:inf_10}{{3.9}{46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Exercises}{46}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Degrees of freedom}{48}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Distribution of the sample mean when sample size is 4 or 200}}{49}}
\newlabel{fig:inf_11}{{3.10}{49}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Distribution of the sample mean when sample size is 4 or 200}}{49}}
\newlabel{fig:inf_12}{{3.11}{49}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Different regression lines for different values of y if x=3}}{50}}
\newlabel{fig:inf_13}{{3.12}{50}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Inference II: hypothesis testing, $p$-values and beyond}{52}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}The null-hypothesis}{52}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Distribution of the sample slope}}{53}}
\newlabel{fig:inf_14}{{4.1}{53}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces The histogram of 1000 sample slopes and its corresponding theoretical t-distribution with 38 degrees of freedom}}{54}}
\newlabel{fig:inf_117}{{4.2}{54}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}The $p$-value}{54}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Probability of a T-value larger than 0.53}}{55}}
\newlabel{fig:inf_17}{{4.3}{55}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Probability of finding a T-value smaller than -0.53}}{56}}
\newlabel{fig:inf_18}{{4.4}{56}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Hypothesis testing}{56}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces The vertical line represents a T-value of 0.53}}{57}}
\newlabel{fig:inf_19}{{4.5}{57}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Exercises}{58}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Type I and Type II errors in decision making}{60}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Different t-distributions of the sample slope if the population slope equals 0 (left curve in blue), and if the population slope equals 1 (right curve in red)}}{62}}
\newlabel{fig:inf_20}{{4.6}{62}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Different t-distributions of the sample slope if the population slope equals 0 (left curve in blue), and if the population slope equals 1 (right curve in red)}}{62}}
\newlabel{fig:inf_21}{{4.7}{62}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Exercises}{63}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Different t-distributions of the sample slope if the population slope equals 0 (left curve), and if the population slope equals 1 (right curve)}}{64}}
\newlabel{fig:inf_22}{{4.8}{64}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Different t-distributions of the sample slope if the population slope equals 0 (left curve in blue), and if the population slope equals 1 (right curve in red)}}{64}}
\newlabel{fig:inf_23}{{4.9}{64}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Statistical power}{65}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Different t-distributions of the sample slope if the population slope equals 0 (left curve in blue), and if the population slope equals 1 (right curve in red)}}{66}}
\newlabel{fig:inf_24}{{4.10}{66}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Exercises}{67}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Power analysis}{67}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces G*power output for a simple regression analysis.}}{68}}
\newlabel{fig:gpower}{{4.11}{68}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Exercises}{68}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Illustration of exercise}}{69}}
\newlabel{fig:bla}{{4.12}{69}}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Criticism on null-hypothesis testing and $p$-values}{69}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.1}Exercise}{73}}
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Relationship between $p$-values and confidence intervals}{73}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces Regression of y on x, with the population line in black and the sample line in blue}}{74}}
\newlabel{fig:inf_28}{{4.13}{74}}
\@writefile{toc}{\contentsline {section}{\numberline {4.9}Inference using SPSS}{74}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces Output for a simple regression analysis.}}{75}}
\newlabel{fig:inf_29}{{4.14}{75}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.1}Exercises}{76}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Multivariate regression}{78}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Explained and unexplained variance}{78}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}More than one predictor}{79}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}R-squared}{80}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Multicollinearity}{82}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Part of Cape Fur Seal Data.}}{82}}
\newlabel{tab:multi_2}{{5.1}{82}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Regression table for predicting age from height.}}{82}}
\newlabel{tab:multi_2a}{{5.2}{82}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Regression table for predicting age from heart}}{83}}
\newlabel{tab:multi_2b}{{5.3}{83}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Regression table for predicting age from heart and weight}}{83}}
\newlabel{tab:multi_2c}{{5.4}{83}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Multiple regression and inference}{84}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Multiple regression in SPSS}{85}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces SPSS output of a linear model (multiple regression) for predicting the weight of books.}}{85}}
\newlabel{fig:multi1}{{5.1}{85}}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Simpson's paradox}{86}}
\@writefile{toc}{\contentsline {section}{\numberline {5.8}Exercises}{88}}
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces Regression table for predicting volume from height and girth.}}{89}}
\newlabel{tab:multi_5}{{5.5}{89}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces A scatterplot for the relationship between height and volume of a tree}}{90}}
\newlabel{fig:multi_7}{{5.2}{90}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces A scatterplot for the relationship between girth and volume of a tree}}{90}}
\newlabel{fig:multi_8}{{5.3}{90}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Categorical predictor variables}{91}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Dummy coding}{91}}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces Bus trips to Paris.}}{92}}
\newlabel{tab:dummy_1}{{6.1}{92}}
\@writefile{lot}{\contentsline {table}{\numberline {6.2}{\ignorespaces Bus trips to Paris.}}{92}}
\newlabel{tab:dummy_2}{{6.2}{92}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Relation between dummy variable window and price}}{93}}
\newlabel{fig:dummy_3}{{6.1}{93}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Using regression to describe group means}{93}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Relation between type of seat and price}}{94}}
\newlabel{fig:dummy_4}{{6.2}{94}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Relation between type of seat and price, with the regression line being not quite the least squares }}{94}}
\newlabel{fig:dummy_6}{{6.3}{94}}
\@writefile{lot}{\contentsline {table}{\numberline {6.3}{\ignorespaces Bus trips to Paris.}}{95}}
\newlabel{tab:dummy_5}{{6.3}{95}}
\@writefile{lot}{\contentsline {table}{\numberline {6.4}{\ignorespaces Bus trips to Paris.}}{95}}
\newlabel{tab:dummy_7}{{6.4}{95}}
\newlabel{weight}{{6.7}{95}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Relation between type of seat and price, with the regression line being not quite the least squares }}{96}}
\newlabel{fig:dummy_8}{{6.4}{96}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Testing hypotheses about group means}{96}}
\@writefile{lot}{\contentsline {table}{\numberline {6.5}{\ignorespaces Yield by treatment.}}{97}}
\newlabel{tab:dummy_9}{{6.5}{97}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Regression analysis using a dummy variable in SPSS}{97}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces SPSS output of a regression analysis of weight on treatment.}}{98}}
\newlabel{fig:dummy_10}{{6.5}{98}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces SPSS output of a regression analysis of weight on treatment.}}{99}}
\newlabel{fig:dummy_11}{{6.6}{99}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Exercise}{99}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces SPSS output of a regression analysis of height on sex.}}{99}}
\newlabel{fig:dummy_12}{{6.7}{99}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces SPSS output of a regression analysis of height on ethnicity.}}{100}}
\newlabel{fig:dummy_13}{{6.8}{100}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.9}{\ignorespaces SPSS output of a regression analysis of height on milk.}}{100}}
\newlabel{fig:dummy_14}{{6.9}{100}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Dummy coding for more than two groups}{101}}
\newlabel{tab:dummy}{{6.5}{102}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.1}Exercise}{102}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Analyzing categorical predictor variables in SPSS}{103}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.1}Treating dummy variables quantitatively}{103}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.10}{\ignorespaces Output of a regression analysis on two dummy variables, using the keyword WITH.}}{104}}
\newlabel{tab:dummy_21}{{6.10}{104}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.2}Treating the original variable qualitatively}{105}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.11}{\ignorespaces Output of a regression analysis on the original variable, using the keyword BY.}}{106}}
\newlabel{fig:dummy_22}{{6.11}{106}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.3}Reporting ANOVA}{107}}
\@writefile{toc}{\contentsline {section}{\numberline {6.7}$F$-test for multiple group comparisons}{107}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.12}{\ignorespaces The F-distribution with 2 model degrees of freedom and 156 error degrees of freedom}}{108}}
\newlabel{fig:dummy_22}{{6.12}{108}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.13}{\ignorespaces The vertical line represents a T-value of -2.40}}{109}}
\newlabel{fig:dummy_23}{{6.13}{109}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.14}{\ignorespaces The F-distribution with 1 model degrees of freedom and 40 error degrees of freedom}}{109}}
\newlabel{fig:dummy_24}{{6.14}{109}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Moderation: testing interaction effects}{111}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Categorical by linear interaction}{111}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Exercises}{118}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Interaction with two dummy variables}{119}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}More than two groups}{121}}
\@writefile{toc}{\contentsline {subsubsection}{Exercises}{124}}
\@writefile{toc}{\contentsline {subsubsection}{Answers}{124}}
\@writefile{toc}{\contentsline {section}{\numberline {7.4}Linear by linear interaction}{124}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Assumptions of linear models RUYA}{125}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.0.1}Independence}{125}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.0.2}Linearity (additivity)}{130}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.0.3}Homogeneity of variance}{130}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.0.4}Residuals normally distributed}{130}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Testing assumptions}{130}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.1}Independence}{130}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.2}Linearity (additivity)}{130}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.3}Homogeneity of variance}{130}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.4}Residuals normally distributed}{130}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.5}What to do when assumptions are violated?}{130}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.6}nonlinearity}{130}}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Linear modelling: more advanced topics}{132}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.0.1}Planned comparisons}{132}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.0.2}Testing more than one contrast}{138}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.0.3}Post-hoc comparisons}{139}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.0.4}Posthoc tests for complex contrasts}{142}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.0.5}Fishing expeditions}{142}}
\@writefile{toc}{\contentsline {subsubsection}{Exercises}{143}}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}When assumptions are not met: non-parametric alternatives}{145}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Spearman's rho}{149}}
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Kendall rank-order correlation coefficient $T$}{151}}
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Kruskall-Wallis test for group comparisons}{153}}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Linear mixed modelling: introduction}{155}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}Fixed effects and random effects}{155}}
\@writefile{toc}{\contentsline {section}{\numberline {11.2}Pre-post intervention design}{159}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.1}Exercises}{164}}
\@writefile{toc}{\contentsline {subsubsection}{Answers:}{167}}
\@writefile{toc}{\contentsline {section}{\numberline {11.3}Pre-mid-post intervention design}{170}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.1}Exercises}{173}}
\@writefile{toc}{\contentsline {section}{\numberline {11.4}Pre-mid-post intervention design: linear effects}{175}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.4.1}Exercises}{178}}
\@writefile{toc}{\contentsline {section}{\numberline {11.5}Linear mixed models and interaction effects}{182}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.5.1}Exercises}{187}}
\@writefile{toc}{\contentsline {section}{\numberline {11.6}Mixed designs}{191}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.6.1}Exercises}{192}}
\@writefile{toc}{\contentsline {section}{\numberline {11.7}Mixed design with a linear effect}{195}}
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Non-parametric alternatives for linear mixed models}{200}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {12.1}Checking assumptions}{200}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.1}{\ignorespaces Boxplot of the imaginary speed skating data}}{201}}
\newlabel{fig:nonparmixed_1}{{12.1}{201}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.2}{\ignorespaces Residuals of the speedskating data with a linear mixed model}}{202}}
\newlabel{fig:nonparmixed_2}{{12.2}{202}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.3}{\ignorespaces Histogram of the residuals of the speedskating data with a linear mixed model}}{202}}
\newlabel{fig:nonparmixed_3}{{12.3}{202}}
\@writefile{toc}{\contentsline {section}{\numberline {12.2}Friedman's test for $k$ measures}{203}}
\@writefile{lot}{\contentsline {table}{\numberline {12.1}{\ignorespaces The speedskating data in wide format.}}{203}}
\newlabel{tab:nonparmixed_4}{{12.1}{203}}
\@writefile{lot}{\contentsline {table}{\numberline {12.2}{\ignorespaces Row-wise ranks of the speedskating data.}}{204}}
\newlabel{tab:nonparmixed_5}{{12.2}{204}}
\@writefile{lot}{\contentsline {table}{\numberline {12.3}{\ignorespaces The raw skating data in random order.}}{205}}
\newlabel{tab:nonparmixed_26}{{12.3}{205}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.4}{\ignorespaces Histogram of 1000 possible values for Fr given that the null-hypothesis is true, for 12 speedskaters}}{206}}
\newlabel{fig:nonparmixed_36}{{12.4}{206}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.5}{\ignorespaces Histogram of 1000 possible values for Fr given that the null-hypothesis is true, for 120 speedskaters}}{207}}
\newlabel{fig:nonparmixed_46}{{12.5}{207}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.6}{\ignorespaces The distrbution of Fr under the null-hypothesis, overlain with a chi-square distribution with 2 degrees of freedom}}{207}}
\newlabel{fig:nonparmixed_56}{{12.6}{207}}
\@writefile{toc}{\contentsline {section}{\numberline {12.3}How to perform Friedman's test in SPSS}{208}}
\@writefile{lot}{\contentsline {table}{\numberline {12.4}{\ignorespaces The raw skating data in long data format.}}{208}}
\newlabel{tab:nonparmixed_6}{{12.4}{208}}
\@writefile{lot}{\contentsline {table}{\numberline {12.5}{\ignorespaces The raw skating data in wide data format after CASETOVARS}}{208}}
\newlabel{tab:nonparmixed_7}{{12.5}{208}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.7}{\ignorespaces SPSS output of the Friedman test.}}{209}}
\newlabel{fig:friedman1}{{12.7}{209}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.8}{\ignorespaces SPSS output of the Friedman test with the exact p-value.}}{210}}
\newlabel{fig:friedman2}{{12.8}{210}}
\@writefile{toc}{\contentsline {section}{\numberline {12.4}Wilcoxon's signed ranks test for 2 measures}{210}}
\@writefile{lot}{\contentsline {table}{\numberline {12.6}{\ignorespaces The raw skating data and the computations for Wilcoxon signed ranks test}}{211}}
\newlabel{tab:nonparmixed_77}{{12.6}{211}}
\@writefile{toc}{\contentsline {section}{\numberline {12.5}How to perform Wilcoxon's signed ranks test in SPSS}{212}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.9}{\ignorespaces SPSS output of the Wilcoxon test.}}{213}}
\newlabel{fig:wilcoxon1}{{12.9}{213}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.10}{\ignorespaces SPSS output of the Friedman test for two measures.}}{214}}
\newlabel{fig:friedman3}{{12.10}{214}}
\@writefile{toc}{\contentsline {section}{\numberline {12.6}Ties}{214}}
\@writefile{toc}{\contentsline {section}{\numberline {12.7}Exercises}{215}}
\newlabel{ref:friedmanmood1}{{7}{216}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.11}{\ignorespaces SPSS output of a Friedman test.}}{217}}
\newlabel{fig:friedmanmood1}{{12.11}{217}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.12}{\ignorespaces Residual plot after a linear mixed model analysis}}{218}}
\newlabel{fig:nonparmixed_11a1}{{12.12}{218}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.13}{\ignorespaces Residual plot after a linear mixed model analysis}}{218}}
\newlabel{fig:nonparmixed_11a2}{{12.13}{218}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.14}{\ignorespaces Histogram of residuals after a linear mixed model analysis}}{219}}
\newlabel{fig:nonparmixed_11b}{{12.14}{219}}
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Generalized linear models part I: logistic regression}{220}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {13.1}Introduction}{220}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.1}{\ignorespaces Density function of the normal distribution, with mean 0 and variance 4 (standard deviation 2)}}{221}}
\newlabel{fig:gen_1}{{13.1}{221}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.2}{\ignorespaces Even if residuals are really discrete, the normal distribution can be a good approximation of their distribution}}{222}}
\newlabel{fig:gen_2}{{13.2}{222}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.3}{\ignorespaces Count data example where the normal distribution is not a good approximation of the distribution of the residuals}}{223}}
\newlabel{fig:gen_3}{{13.3}{223}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.4}{\ignorespaces Dichotomous data example where the normal distribution is not a good approximation of the distribution of the residuals}}{223}}
\newlabel{fig:gen_4}{{13.4}{223}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.5}{\ignorespaces Data example}}{224}}
\newlabel{fig:gen_5}{{13.5}{224}}
\@writefile{toc}{\contentsline {section}{\numberline {13.2}Logistic regression}{224}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.6}{\ignorespaces Example exam data with a linear regression line}}{225}}
\newlabel{fig:gen_6}{{13.6}{225}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.7}{\ignorespaces Residuals as a function of age, after a linear regression analysis of the exam data}}{225}}
\newlabel{fig:gen_7}{{13.7}{225}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2.1}Bernoulli distribution}{226}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2.2}Odds and logodds}{227}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.8}{\ignorespaces The relationship between a probability and the natural logarithm of the corresponding odds}}{229}}
\newlabel{fig:gen_8}{{13.8}{229}}
\newlabel{eq:logistic1}{{13.13}{230}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2.3}Exercises}{230}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2.4}Logistic link function}{232}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.9}{\ignorespaces Example of a linear model for the logit of probabilities of passing an exam}}{233}}
\newlabel{fig:gen_9}{{13.9}{233}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.10}{\ignorespaces Example with logodds transformed into probabilties (vertical axis)}}{234}}
\newlabel{fig:gen_10}{{13.10}{234}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.11}{\ignorespaces Transformed regression line and raw data points}}{235}}
\newlabel{fig:gen_11}{{13.11}{235}}
\@writefile{toc}{\contentsline {section}{\numberline {13.3}Logistic regression in SPSS}{235}}
\@writefile{lot}{\contentsline {table}{\numberline {13.1}{\ignorespaces Taking the train to Paris data.}}{235}}
\newlabel{tab:gen_12}{{13.1}{235}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.12}{\ignorespaces SPSS output of a generalized linear model for predicting taking the train from income.}}{237}}
\newlabel{fig:train1}{{13.12}{237}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.1}Exercises}{238}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.13}{\ignorespaces SPSS output of a generalized linear model for predicting taking the train from purpose of the trip.}}{239}}
\newlabel{fig:train2}{{13.13}{239}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.14}{\ignorespaces SPSS output of a generalized linear model for predicting taking the train from purpose of the trip.}}{240}}
\newlabel{fig:train3}{{13.14}{240}}
\@writefile{toc}{\contentsline {chapter}{\numberline {14}Generalized linear models for count data: Poisson regression}{242}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {14.1}Poisson regression}{242}}
\@writefile{lot}{\contentsline {table}{\numberline {14.1}{\ignorespaces Scores on an assignment.}}{242}}
\newlabel{tab:gen_14}{{14.1}{242}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.1}{\ignorespaces Count data example where the normal distribution is not a good approximation of the distribution of the residuals}}{243}}
\newlabel{fig:gen_15}{{14.1}{243}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.2}{\ignorespaces Poisson distribution with lambda=1.17}}{245}}
\newlabel{fig:gen_16}{{14.2}{245}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.3}{\ignorespaces Poisson distribution with lambda=0.85}}{245}}
\newlabel{fig:gen_17}{{14.3}{245}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.4}{\ignorespaces Poisson distribution with lambda=1.60}}{246}}
\newlabel{fig:gen_18}{{14.4}{246}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.5}{\ignorespaces Three different Poisson distributions with lambdas 0.85, 1.17, and 1.60, for three different kinds of students}}{246}}
\newlabel{fig:gen_19}{{14.5}{246}}
\@writefile{toc}{\contentsline {section}{\numberline {14.2}Poisson regression in SPSS}{247}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.6}{\ignorespaces SPSS output of a generalized linear model for predicting assignments scores from the average of previous assignments.}}{247}}
\newlabel{fig:assignment1}{{14.6}{247}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.7}{\ignorespaces SPSS output of a generalized linear model for predicting assignments scores from the degree that is studied for.}}{248}}
\newlabel{fig:assignment2}{{14.7}{248}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.8}{\ignorespaces SPSS output of a generalized linear model for predicting assignments scores from the degree that is studied for.}}{249}}
\newlabel{fig:assignment3}{{14.8}{249}}
\@writefile{toc}{\contentsline {section}{\numberline {14.3}Interaction effects in Poisson models}{249}}
\@writefile{lot}{\contentsline {table}{\numberline {14.2}{\ignorespaces Counts of adult survivors on the Titanic.}}{250}}
\newlabel{tab:gen_20}{{14.2}{250}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.9}{\ignorespaces SPSS output of a generalized linear model for predicting numbers of men and women onboard the Titanic.}}{250}}
\newlabel{fig:titanic1}{{14.9}{250}}
\@writefile{lot}{\contentsline {table}{\numberline {14.3}{\ignorespaces Counts of adults on the Titanic.}}{251}}
\newlabel{tab:gen_21}{{14.3}{251}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.10}{\ignorespaces SPSS output of a generalized linear model for predicting numbers of men and women that perished and survived onboard the Titanic.}}{252}}
\newlabel{fig:titanic2}{{14.10}{252}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.11}{\ignorespaces SPSS output of a generalized linear model for predicting numbers of men and women that perished and survived onboard the Titanic.}}{253}}
\newlabel{fig:titanic3}{{14.11}{253}}
\@writefile{toc}{\contentsline {section}{\numberline {14.4}Crosstabulation and the Pearson chi-square statistic}{254}}
\@writefile{lot}{\contentsline {table}{\numberline {14.4}{\ignorespaces Counts of adult survivors and non-survivors on the Titanic.}}{254}}
\newlabel{tab:gen_24}{{14.4}{254}}
\@writefile{lot}{\contentsline {table}{\numberline {14.5}{\ignorespaces Counts of adult survivors and non-survivors on the Titanic.}}{254}}
\newlabel{tab:gen_25}{{14.5}{254}}
\@writefile{lot}{\contentsline {table}{\numberline {14.6}{\ignorespaces Counts of adult survivors and non-survivors on the Titanic.}}{255}}
\newlabel{tab:gen_26}{{14.6}{255}}
\@writefile{lot}{\contentsline {table}{\numberline {14.7}{\ignorespaces Expected numbers of adult survivors and non-survivors on the Titanic.}}{255}}
\newlabel{tab:gen_27}{{14.7}{255}}
\@writefile{toc}{\contentsline {section}{\numberline {14.5}Poisson regression or logistic regression?}{256}}
\@writefile{lot}{\contentsline {table}{\numberline {14.8}{\ignorespaces Individual data of adult survivors and non-survivors on the Titanic.}}{257}}
\newlabel{tab:gen_28}{{14.8}{257}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.12}{\ignorespaces SPSS output of a generalized linear model for predicting numbers of men and women that perished and survived onboard the Titanic.}}{258}}
\newlabel{fig:titanic4}{{14.12}{258}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.13}{\ignorespaces SPSS output of a generalized linear model for predicting numbers of men and women that perished and survived onboard the Titanic.}}{259}}
\newlabel{fig:titanic5}{{14.13}{259}}
