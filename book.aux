\relax 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Exploring your data}{5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Types of variables}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Continuous, ordinal, and categorical variables}{5}}
\@writefile{toc}{\contentsline {subsubsection}{Exercises}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Qualitative and quantitative treatment of variables in data analysis}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Dependent and independent variables}{7}}
\@writefile{toc}{\contentsline {subsubsection}{Exercises}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Distributions}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces A frequency distribution}}{8}}
\newlabel{fig:distr_1}{{1.1}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces A histogram}}{9}}
\newlabel{fig:distr_2}{{1.2}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces A histogram}}{9}}
\newlabel{fig:distr_3}{{1.3}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Mean, median and mode}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}The mean}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}The median}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}The mode}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Variance}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Sum of squares}{11}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Linear modelling: introduction FULYA}{14}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Linear relationships}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Pearson correlation}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Simple regression with a continuous predictor}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Predicting the dependent variable}{14}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Multivariate regression}{15}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Explained and unexplained variance}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}More than one predictor}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}R-squared}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Multicollinearity}{19}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Part of Cape Fur Seal Data.}}{19}}
\newlabel{tab:multi_2}{{3.1}{19}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Multiple regression in SPSS}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces SPSS output of a linear model (multiple regression) for predicting the weight of books.}}{21}}
\newlabel{fig:multi1}{{3.1}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Simpson's paradox}{22}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Exercises}{24}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Regression table for predicting volume from height and girth.}}{25}}
\newlabel{tab:multi_5}{{3.2}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces A scatterplot for the relationship between height and volume of a tree}}{26}}
\newlabel{fig:multi_7}{{3.2}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces A scatterplot for the relationship between girth and volume of a tree}}{26}}
\newlabel{fig:multi_8}{{3.3}{26}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Inference I: random samples, standard errors and confidence intervals}{27}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The relationship between temperature and volume in a sample of 200 bottles}}{28}}
\newlabel{fig:inf_0}{{4.1}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Population data and sample data}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces The relationship between temperature and volume in all 80,000 bottles}}{29}}
\newlabel{fig:inf_1}{{4.2}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Random sampling and the standard error}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Distribution of the sample mean when population variance is 225 and sample size equals 200}}{30}}
\newlabel{fig:inf_3}{{4.3}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Distribution of the sample mean when population variance is 225 and sample size equals 200}}{31}}
\newlabel{fig:inf_5}{{4.4}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Distribution of the sample slope when sample size is 2 and when sample size is 20}}{32}}
\newlabel{fig:inf_7}{{4.5}{32}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}$t$-distributions}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Difference in the shapes of a normal distribution and a t-distribution}}{34}}
\newlabel{fig:inf_8}{{4.6}{34}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}$T$-statistics}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces The shape of the distribution of sample slopes depends on sample size}}{35}}
\newlabel{fig:inf_9}{{4.7}{35}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces The standard normal distribution and the probability of a Z-score lower than -1.06}}{36}}
\newlabel{fig:inf_9b}{{4.8}{36}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Hypothetical population slopes}{36}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Confidence intervals for smaller sample sizes}{38}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Quantiles for the normal and several t-distributions.}}{39}}
\newlabel{tab:nonparmixed_4}{{4.1}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Two t-distributions when sample size is 4 or 200, with corresponding 95 percent intervals}}{40}}
\newlabel{fig:inf_10}{{4.9}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Exercises}{40}}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Degrees of freedom}{41}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Distribution of the sample mean when sample size is 4 or 200}}{42}}
\newlabel{fig:inf_11}{{4.10}{42}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Distribution of the sample mean when sample size is 4 or 200}}{42}}
\newlabel{fig:inf_12}{{4.11}{42}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Different regression lines for different values of y if x=3}}{43}}
\newlabel{fig:inf_13}{{4.12}{43}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Inference II: hypothesis testing, $p$-values and beyond}{44}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}The null-hypothesis}{44}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Distribution of the sample mean when population variance is 25 and sample size equals 200}}{45}}
\newlabel{fig:inf_14}{{5.1}{45}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}The $p$-value}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Different regression lines for different values of y if x=3}}{46}}
\newlabel{fig:inf_17}{{5.2}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Different regression lines for different values of y if x=3}}{47}}
\newlabel{fig:inf_18}{{5.3}{47}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Hypothesis testing}{47}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Different regression lines for different values of y if x=3}}{48}}
\newlabel{fig:inf_19}{{5.4}{48}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Different regression lines for different values of y if x=3}}{50}}
\newlabel{fig:inf_20}{{5.5}{50}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Different regression lines for different values of y if x=3}}{50}}
\newlabel{fig:inf_21}{{5.6}{50}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Different regression lines for different values of y if x=3}}{52}}
\newlabel{fig:inf_22}{{5.7}{52}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Relationship between $p$-value and confidence intervals}{52}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Different regression lines for different values of y if x=3}}{53}}
\newlabel{fig:inf_23}{{5.8}{53}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Criticism on null-hypothesis testing and $p$-values}{53}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Inference: from sample to population}{53}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Categorical predictor variables}{54}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Dummy coding}{54}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Predicting group means}{54}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Dummy coding for more than two groups}{54}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Comparing more than two groups}{54}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Analyzing categorical predictor variables}{55}}
\@writefile{toc}{\contentsline {subsubsection}{Treating dummy variables quantitatively}{55}}
\@writefile{toc}{\contentsline {subsubsection}{Treating the original variable qualitatively}{57}}
\@writefile{toc}{\contentsline {subsubsection}{Reporting one-way ANOVA}{58}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}$F$-test for multiple group comparisons}{58}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Moderation: testing interaction effects}{59}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Categorical by linear interaction}{59}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Exercises}{66}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Interaction with two dummy variables}{67}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}More than two groups}{69}}
\@writefile{toc}{\contentsline {subsubsection}{Exercises}{72}}
\@writefile{toc}{\contentsline {subsubsection}{Answers}{72}}
\@writefile{toc}{\contentsline {section}{\numberline {7.4}Linear by linear interaction}{72}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Assumptions of linear models RUYA}{73}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.0.1}Independence}{73}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.0.2}Linearity (additivity)}{78}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.0.3}Homogeneity of variance}{78}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.0.4}Residuals normally distributed}{78}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Testing assumptions}{78}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.1}Independence}{78}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.2}Linearity (additivity)}{78}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.3}Homogeneity of variance}{78}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.4}Residuals normally distributed}{78}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.5}What to do when assumptions are violated?}{78}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.6}nonlinearity}{78}}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Linear modelling: more advanced topics}{80}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.0.1}Planned comparisons}{80}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.0.2}Testing more than one contrast}{86}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.0.3}Post-hoc comparisons}{87}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.0.4}Posthoc tests for complex contrasts}{90}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.0.5}Fishing expeditions}{90}}
\@writefile{toc}{\contentsline {subsubsection}{Exercises}{91}}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}When assumptions are not met: non-parametric alternatives}{93}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Spearman's rho}{97}}
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Kendall rank-order correlation coefficient $T$}{99}}
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Kruskall-Wallis test for group comparisons}{101}}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Linear mixed modelling: introduction}{103}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}Fixed effects and random effects}{103}}
\@writefile{toc}{\contentsline {section}{\numberline {11.2}Pre-post intervention design}{107}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2.1}Exercises}{112}}
\@writefile{toc}{\contentsline {subsubsection}{Answers:}{115}}
\@writefile{toc}{\contentsline {section}{\numberline {11.3}Pre-mid-post intervention design}{118}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3.1}Exercises}{121}}
\@writefile{toc}{\contentsline {section}{\numberline {11.4}Pre-mid-post intervention design: linear effects}{123}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.4.1}Exercises}{126}}
\@writefile{toc}{\contentsline {section}{\numberline {11.5}Linear mixed models and interaction effects}{130}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.5.1}Exercises}{135}}
\@writefile{toc}{\contentsline {section}{\numberline {11.6}Mixed designs}{139}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.6.1}Exercises}{140}}
\@writefile{toc}{\contentsline {section}{\numberline {11.7}Mixed design with a linear effect}{143}}
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Non-parametric alternatives for linear mixed models}{148}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {12.1}Checking assumptions}{148}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.1}{\ignorespaces Boxplot of the imaginary speed skating data}}{149}}
\newlabel{fig:nonparmixed_1}{{12.1}{149}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.2}{\ignorespaces Residuals of the speedskating data with a linear mixed model}}{150}}
\newlabel{fig:nonparmixed_2}{{12.2}{150}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.3}{\ignorespaces Histogram of the residuals of the speedskating data with a linear mixed model}}{150}}
\newlabel{fig:nonparmixed_3}{{12.3}{150}}
\@writefile{toc}{\contentsline {section}{\numberline {12.2}Friedman's test for $k$ measures}{151}}
\@writefile{lot}{\contentsline {table}{\numberline {12.1}{\ignorespaces The speedskating data in wide format.}}{151}}
\newlabel{tab:nonparmixed_4}{{12.1}{151}}
\@writefile{lot}{\contentsline {table}{\numberline {12.2}{\ignorespaces Row-wise ranks of the speedskating data.}}{152}}
\newlabel{tab:nonparmixed_5}{{12.2}{152}}
\@writefile{lot}{\contentsline {table}{\numberline {12.3}{\ignorespaces The raw skating data in random order.}}{153}}
\newlabel{tab:nonparmixed_26}{{12.3}{153}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.4}{\ignorespaces Histogram of 1000 possible values for Fr given that the null-hypothesis is true, for 12 speedskaters}}{154}}
\newlabel{fig:nonparmixed_36}{{12.4}{154}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.5}{\ignorespaces Histogram of 1000 possible values for Fr given that the null-hypothesis is true, for 120 speedskaters}}{155}}
\newlabel{fig:nonparmixed_46}{{12.5}{155}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.6}{\ignorespaces The distrbution of Fr under the null-hypothesis, overlain with a chi-square distribution with 2 degrees of freedom}}{155}}
\newlabel{fig:nonparmixed_56}{{12.6}{155}}
\@writefile{toc}{\contentsline {section}{\numberline {12.3}How to perform Friedman's test in SPSS}{156}}
\@writefile{lot}{\contentsline {table}{\numberline {12.4}{\ignorespaces The raw skating data in long data format.}}{156}}
\newlabel{tab:nonparmixed_6}{{12.4}{156}}
\@writefile{lot}{\contentsline {table}{\numberline {12.5}{\ignorespaces The raw skating data in wide data format after CASETOVARS}}{156}}
\newlabel{tab:nonparmixed_7}{{12.5}{156}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.7}{\ignorespaces SPSS output of the Friedman test.}}{157}}
\newlabel{fig:friedman1}{{12.7}{157}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.8}{\ignorespaces SPSS output of the Friedman test with the exact p-value.}}{158}}
\newlabel{fig:friedman2}{{12.8}{158}}
\@writefile{toc}{\contentsline {section}{\numberline {12.4}Wilcoxon's signed ranks test for 2 measures}{158}}
\@writefile{lot}{\contentsline {table}{\numberline {12.6}{\ignorespaces The raw skating data and the computations for Wilcoxon signed ranks test}}{159}}
\newlabel{tab:nonparmixed_77}{{12.6}{159}}
\@writefile{toc}{\contentsline {section}{\numberline {12.5}How to perform Wilcoxon's signed ranks test in SPSS}{160}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.9}{\ignorespaces SPSS output of the Wilcoxon test.}}{161}}
\newlabel{fig:wilcoxon1}{{12.9}{161}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.10}{\ignorespaces SPSS output of the Friedman test for two measures.}}{162}}
\newlabel{fig:friedman3}{{12.10}{162}}
\@writefile{toc}{\contentsline {section}{\numberline {12.6}Ties}{162}}
\@writefile{toc}{\contentsline {section}{\numberline {12.7}Exercises}{163}}
\newlabel{ref:friedmanmood1}{{7}{164}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.11}{\ignorespaces SPSS output of a Friedman test.}}{165}}
\newlabel{fig:friedmanmood1}{{12.11}{165}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.12}{\ignorespaces Residual plot after a linear mixed model analysis}}{166}}
\newlabel{fig:nonparmixed_11a1}{{12.12}{166}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.13}{\ignorespaces Residual plot after a linear mixed model analysis}}{166}}
\newlabel{fig:nonparmixed_11a2}{{12.13}{166}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.14}{\ignorespaces Histogram of residuals after a linear mixed model analysis}}{167}}
\newlabel{fig:nonparmixed_11b}{{12.14}{167}}
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Generalized linear models part I: logistic regression}{168}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {13.1}Introduction}{168}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.1}{\ignorespaces Density function of the normal distribution, with mean 0 and variance 4 (standard deviation 2)}}{169}}
\newlabel{fig:gen_1}{{13.1}{169}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.2}{\ignorespaces Even if residuals are really discrete, the normal distribution can be a good approximation of their distribution}}{170}}
\newlabel{fig:gen_2}{{13.2}{170}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.3}{\ignorespaces Count data example where the normal distribution is not a good approximation of the distribution of the residuals}}{171}}
\newlabel{fig:gen_3}{{13.3}{171}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.4}{\ignorespaces Dichotomous data example where the normal distribution is not a good approximation of the distribution of the residuals}}{171}}
\newlabel{fig:gen_4}{{13.4}{171}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.5}{\ignorespaces Data example}}{172}}
\newlabel{fig:gen_5}{{13.5}{172}}
\@writefile{toc}{\contentsline {section}{\numberline {13.2}Logistic regression}{172}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.6}{\ignorespaces Example exam data with a linear regression line}}{173}}
\newlabel{fig:gen_6}{{13.6}{173}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.7}{\ignorespaces Residuals as a function of age, after a linear regression analysis of the exam data}}{173}}
\newlabel{fig:gen_7}{{13.7}{173}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2.1}Bernoulli distribution}{174}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2.2}Odds and logodds}{175}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.8}{\ignorespaces The relationship between a probability and the natural logarithm of the corresponding odds}}{177}}
\newlabel{fig:gen_8}{{13.8}{177}}
\newlabel{eq:logistic1}{{13.13}{178}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2.3}Exercises}{178}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2.4}Logistic link function}{180}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.9}{\ignorespaces Example of a linear model for the logit of probabilities of passing an exam}}{181}}
\newlabel{fig:gen_9}{{13.9}{181}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.10}{\ignorespaces Example with logodds transformed into probabilties (vertical axis)}}{182}}
\newlabel{fig:gen_10}{{13.10}{182}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.11}{\ignorespaces Transformed regression line and raw data points}}{183}}
\newlabel{fig:gen_11}{{13.11}{183}}
\@writefile{toc}{\contentsline {section}{\numberline {13.3}Logistic regression in SPSS}{183}}
\@writefile{lot}{\contentsline {table}{\numberline {13.1}{\ignorespaces Taking the train to Paris data.}}{183}}
\newlabel{tab:gen_12}{{13.1}{183}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.12}{\ignorespaces SPSS output of a generalized linear model for predicting taking the train from income.}}{185}}
\newlabel{fig:train1}{{13.12}{185}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.1}Exercises}{186}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.13}{\ignorespaces SPSS output of a generalized linear model for predicting taking the train from purpose of the trip.}}{187}}
\newlabel{fig:train2}{{13.13}{187}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.14}{\ignorespaces SPSS output of a generalized linear model for predicting taking the train from purpose of the trip.}}{188}}
\newlabel{fig:train3}{{13.14}{188}}
\@writefile{toc}{\contentsline {chapter}{\numberline {14}Generalized linear models for count data: Poisson regression}{190}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {14.1}Poisson regression}{190}}
\@writefile{lot}{\contentsline {table}{\numberline {14.1}{\ignorespaces Scores on an assignment.}}{190}}
\newlabel{tab:gen_14}{{14.1}{190}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.1}{\ignorespaces Count data example where the normal distribution is not a good approximation of the distribution of the residuals}}{191}}
\newlabel{fig:gen_15}{{14.1}{191}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.2}{\ignorespaces Poisson distribution with lambda=1.17}}{193}}
\newlabel{fig:gen_16}{{14.2}{193}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.3}{\ignorespaces Poisson distribution with lambda=0.85}}{193}}
\newlabel{fig:gen_17}{{14.3}{193}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.4}{\ignorespaces Poisson distribution with lambda=1.60}}{194}}
\newlabel{fig:gen_18}{{14.4}{194}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.5}{\ignorespaces Three different Poisson distributions with lambdas 0.85, 1.17, and 1.60, for three different kinds of students}}{194}}
\newlabel{fig:gen_19}{{14.5}{194}}
\@writefile{toc}{\contentsline {section}{\numberline {14.2}Poisson regression in SPSS}{195}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.6}{\ignorespaces SPSS output of a generalized linear model for predicting assignments scores from the average of previous assignments.}}{195}}
\newlabel{fig:assignment1}{{14.6}{195}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.7}{\ignorespaces SPSS output of a generalized linear model for predicting assignments scores from the degree that is studied for.}}{196}}
\newlabel{fig:assignment2}{{14.7}{196}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.8}{\ignorespaces SPSS output of a generalized linear model for predicting assignments scores from the degree that is studied for.}}{197}}
\newlabel{fig:assignment3}{{14.8}{197}}
\@writefile{toc}{\contentsline {section}{\numberline {14.3}Interaction effects in Poisson models}{197}}
\@writefile{lot}{\contentsline {table}{\numberline {14.2}{\ignorespaces Counts of adult survivors on the Titanic.}}{198}}
\newlabel{tab:gen_20}{{14.2}{198}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.9}{\ignorespaces SPSS output of a generalized linear model for predicting numbers of men and women onboard the Titanic.}}{198}}
\newlabel{fig:titanic1}{{14.9}{198}}
\@writefile{lot}{\contentsline {table}{\numberline {14.3}{\ignorespaces Counts of adults on the Titanic.}}{199}}
\newlabel{tab:gen_21}{{14.3}{199}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.10}{\ignorespaces SPSS output of a generalized linear model for predicting numbers of men and women that perished and survived onboard the Titanic.}}{200}}
\newlabel{fig:titanic2}{{14.10}{200}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.11}{\ignorespaces SPSS output of a generalized linear model for predicting numbers of men and women that perished and survived onboard the Titanic.}}{201}}
\newlabel{fig:titanic3}{{14.11}{201}}
\@writefile{toc}{\contentsline {section}{\numberline {14.4}Crosstabulation and the Pearson chi-square statistic}{202}}
\@writefile{lot}{\contentsline {table}{\numberline {14.4}{\ignorespaces Counts of adult survivors and non-survivors on the Titanic.}}{202}}
\newlabel{tab:gen_24}{{14.4}{202}}
\@writefile{lot}{\contentsline {table}{\numberline {14.5}{\ignorespaces Counts of adult survivors and non-survivors on the Titanic.}}{202}}
\newlabel{tab:gen_25}{{14.5}{202}}
\@writefile{lot}{\contentsline {table}{\numberline {14.6}{\ignorespaces Counts of adult survivors and non-survivors on the Titanic.}}{203}}
\newlabel{tab:gen_26}{{14.6}{203}}
\@writefile{lot}{\contentsline {table}{\numberline {14.7}{\ignorespaces Expected numbers of adult survivors and non-survivors on the Titanic.}}{203}}
\newlabel{tab:gen_27}{{14.7}{203}}
\@writefile{toc}{\contentsline {section}{\numberline {14.5}Poisson regression or logistic regression?}{204}}
\@writefile{lot}{\contentsline {table}{\numberline {14.8}{\ignorespaces Individual data of adult survivors and non-survivors on the Titanic.}}{205}}
\newlabel{tab:gen_28}{{14.8}{205}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.12}{\ignorespaces SPSS output of a generalized linear model for predicting numbers of men and women that perished and survived onboard the Titanic.}}{206}}
\newlabel{fig:titanic4}{{14.12}{206}}
\@writefile{lof}{\contentsline {figure}{\numberline {14.13}{\ignorespaces SPSS output of a generalized linear model for predicting numbers of men and women that perished and survived onboard the Titanic.}}{207}}
\newlabel{fig:titanic5}{{14.13}{207}}
