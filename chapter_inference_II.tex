\chapter{Inference II: hypothesis testing, $p$-values and beyond}\label{chap:hypothesis}

\section{The null-hypothesis}

Often, data analysis is about finding an answer to the question whether there is a relationship between two variables. In most cases, the question pertains to the population: is there a relationship between variable $y$ and variable $x$ in the population? In many cases, one looks for a linear relationship between two variables.

One common method to answer this question is to analyse a sample of data, apply a linear model, and look at the slope. However, one then knows the slope in the sample, but not the slope in the population. We have seen that the slope in the sample can be very different from the slope in the population. Suppose we find a slope of 1: does that mean there is a slope in the population or that there is no slope in the population?

In inferential data analysis, one often works with two hypotheses: the \textit{null-hypothesis} and the \textit{alternative hypothesis}. The null-hypothesis states that the population slope is equal to 0 and the alternative hypothesis states that there is a slope that is different from 0. Remember that if the population slope is equal to 0, that is saying that there is no linear relationship between $x$ and $y$ (that is, you cannot predict one variable on the basis of the other variable). Therefore, the null-hypothesis states there is no linear relationship between $x$ and $y$ in the population. If there is a slope, whether positive or negative, is the same as saying there is a linear relationship, so the alternative hypothesis states that there is a linear relationship between $x$ and $y$ in the population.

The null-hypothesis is often denoted as $H_0$ and the alternative hypothesis is often denoted as $H_A$. In formula form, we have


\begin{eqnarray}
H_0: \beta_{slope}=0 \\
H_A: \beta_{slope} \neq 0
\end{eqnarray}

The population slope, $\beta_{slope}$, is either 0 or it is not. Our data analysis is then aimed at determining which of these two hypotheses is true. Key is that we do a thought experiment on the null-hypothesis: we wonder what would happen if the population slope would be really 0. In our imagination we draw many samples of a certain size, say 40 data points, and then determine the slope for each sample. Earlier we learned that the many sample slopes would form a histogram in the shape of a $t$-distribution with $n-2=38$ degrees of freedom. For example, suppose we would draw 1000 samples of size 40, then the histogram of the 1000 slopes would be like depicted in Figure \ref{fig:inf_14}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in eval(expr, envir, enclos): object 'bottles' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in data.frame(sample.slope, panel) \%>\% ggplot(aes(x = sample.slope)): could not find function "{}\%>\%"{}}}\end{kframe}
\end{knitrout}

From this histogram we see that all observed sample slopes are well between -0.8 and 0.8. This gives us the information we need. Of course, we have only one sample of data, and we don't know anything about the population data. But we \textit{do} know that \textit{if the population slope is equal to 0}, then it is very unlikely to find a sample slope of say 1 or -1. Thus, if we happen to find a sample slope of say -1, we know that this finding is very unlikely \textit{if we hold the null-hypothesis to be true}. In other words, if the population slope is equal to 0, it would be quite improbable to find a sample slope of -1 or smaller. Therefore, we regard the null-hypothesis to be false, since it does not provide a good explanation of why we found a sample slope of -1. In that case, we say that \textit{we reject the null-hypothesis}.

% \section{$T$-statistics}
%
% In previous sections we looked at the distribution of the slope based on sample data, if you draw many random samples from a population of data points. We saw that nearly always, the slope based on your sample data is different from the slope in the population data. We learned that the shape of the distribution is that of a $t$-distribution. The particular shape of the distribution depends on the degrees of freedom, and we learned that the degrees of freedom is equal to the number of data points in your sample (sample size $n$) minus the number of parameters/coefficients in your linear equation.
%
% We said that the distribution of the regression slope has the \textit{shape} of a $t$-distribution. In order to get a $t$-distribution, you have to standardize the scores. Similar to standardizing other scores to z-scores, by subtracting the mean and dividing by the standard deviation, we too standardize slope estimates into T-scores.
%
% Similar to the normal distribution. If you know a value is 2, then you know nothing, but if you know that a value is 20 standard deviations away from the mean, that is, a $z$-score of 20, then you know that such a value is rather unlikely.
%
% The same is true for the distribution of sample slopes. Only knowing that the sample slope is 1, says nothing, but that the slope is 30 standard errors away from a particular value is saying that such a value is unlikely.
%
% So similar to $z$-scores, we subtract the mean from the sample slope and divide by the standard deviation. If the null-hypothesis is true, the mean of the sample slopes is 0. We also know that the standard deviation of the sample slopes is the standard error.
%
% This standardized slope is called a $T$-statistic. A statistic is a quantity that is based on a calculation using your sample data. For example, using least squares, you determine the slope parameter $b_{slope}$, and you determine the standard error $se$. Next, you compute the $T$-statistic:
%
% \begin{equation}
% T = \frac{b_{slope}-0}{se} = \frac{b_{slope}}{se}
% \end{equation}
%
%
% Figure \ref{fig:inf_15} shows the $t$-distribution with $40-2=38$ degrees of freedom. This is the distribution for the $T$-statistic if our sample size is equal to 40 and the true population slope is equal to 0.
%
%
% <<inf_15,fig.height=4, echo=FALSE, fig.align='center', fig.cap='Different regression lines for different values of y if x=3.'>>=
% data.frame(x)  %>%  ggplot(aes(x=x)) +
%   stat_function(fun = dt, args = list(df=38))  +
%         ylab("density") + xlim(c(-4,4)) + xlab("T")
% @
%
% Suppose the true value of the slope (the slope in the population data) is equal to exactly 0. Then if you analyse a sample of 40 data points, you might find a slope of $b_{slope}=1$, and the standard error turns out to be 2. If we then compute $T$, we get $T=\frac{b_{slope}}{se}=1/2=0.5$. In other words, our slope is half a standard error away from the hypothesised value of 0. Whether this is a lot, depends on the shape of the distribution. For this $T$ we know that it has a $t$-distribution with 38 degrees of freedom. Figure \ref{fig:inf_16} shows this distribution. The tails that each contain 2.5\% are shaded. Thus, if the true slope is 0, and if we would draw a lot of samples and for each sample determine the slope, then 95\% of those slopes will lie within the non-shaded area. The figure also indicates the value for our T-statistic, 0.5. It can be clearly seen that a value of 0.5 lies well within the middle 95\% of the distribution, in other words, a value of 0.5 is not that strange for a $t$-distribution with 38 degrees of freedom.
%
%
% <<inf_16,fig.height=4, echo=FALSE, fig.align='center', fig.cap='Different regression lines for different values of y if x=3.'>>=
%
% df = 38; ncp = 0; limits = c(-5,5)
% lb=-20; ub=qt(0.025, df=df, ncp=ncp)
%     x <- seq(limits[1], limits[2], length.out = 100)
%     xmin <- max(lb, limits[1])
%     xmax <- min(ub, limits[2])
%     areax <- seq(xmin, xmax, length.out = 100)
%     area <- data.frame(x = areax, ymin = 0, ymax = dt(areax, df=df, ncp=ncp))
%     (ggplot()
%      + geom_line(data.frame(x = x, y = dt(x, df=df, ncp=ncp)),
%                  mapping = aes(x = x, y = y))
%      + geom_area(data = area, mapping = aes(x = x,  y = ymax))
%      + scale_x_continuous(limits = limits, breaks=seq(-5,5,1))
%      + geom_area(data = area, mapping = aes(x = seq(qt(0.975, df=df, ncp=ncp), 5, length.out = 100),  y = dt(seq(qt(0.975, df=df, ncp=ncp), 5, length.out = 100), df=df, ncp=ncp)))
%             + geom_vline(xintercept = 0.5)  + xlab("T") )
% @
%
%
%
%
%
%
%
%
%
% Based on our reasoning in the section on confidence intervals, we can construct an interval of reasonable values for the population $T$ by taking the middle 95\% of the distribution.

\section{The $p$-value}

The $p$-value is a probability. It represents the probability of observing certain events, given that the null-hypothesis is true.

In the previous section we saw that if the population slope is 0, and we drew 1000 samples of size 40, we did not observe a sample slope of -1 or smaller. In other words, the frequency of observing a slope of -1 or smaller was 0. If we would draw more samples, we theoretically could observe a sample slope of -1, but the probability that that happens for any new sample we can estimate at less than 1 in a 1000, so less than 0.001.

This estimate of the $p$-value was based on 1000 randomly drawn samples of size 40 and then looking at the frequency of certain values in that data set. But there is a short-cut, for we know that the distribution of sample slopes has a $t$-distribution if we standardize the sample slopes. Therefore we do not have to take 1000 samples and estimate probabilities, but we can look at the $t$-distribution directly, using tables online or in statistical packages.

Figure \ref{fig:inf_117} shows the $t$-distribution that is the theoretical distribution corresponding to the histogram in Figure \ref{fig:inf_14}. If the standard error is equal to 0.19, and the hypothetical population slope is 0, then the $T$-statistic associated with a slope of -1 is equal to $\frac{-1-0}{0.19}=-5.26$. With this value, we can look up in the tables, how often such a value of -5.26 \textit{or smaller} occurs in a $t$-distribution with 38 degrees of freedom (see Chapter \ref{chap:confidence}). In the tables we find that the probability that this occurs is 0.00000294. So, the fact that the $T$-statistic has a $t$-distribution gives us the opportunity to exactly determine certain probabilities, including the $p$-value.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in ggplot(): could not find function "{}ggplot"{}}}\end{kframe}
\end{knitrout}

Now let's suppose we have only one sample of 40 bottles, and we find a slope of 0.1 with a standard error of 0.19. Then this value of 0.1 is $(0.1-0)/0.19=0.53$ standard errors away from 0. Thus, the $T$-statistic is 0.53. We then look at the $t$-distribution with 38 degrees of freedom, and see that such a $T$-value of 0.53 is not very strange: it lies well within the middle 95\% of the $t$-distribution (see Figure \ref{fig:inf_117}).

Let's determine the $p$-value again for this slope of 0.1: we determine the probability that we obtain such a $T$-value of 0.53 or larger. Figure \ref{fig:inf_17} shows the area under the curve for values of $T$ that are larger than 0.53. This area under the curve can be seen as a probability. The total area under the curve of the $t$-distribution amounts to 1. If we know the area of the shaded part of the total area, we can compute the probability of finding $T$-values larger than 0.53.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in ggplot(): could not find function "{}ggplot"{}}}\end{kframe}
\end{knitrout}

In tables online, in books, or available in statistical packages, we can look up how large this area is. It turns out to be 0.3. So, if the population slope is equal to 0 and we draw an infinite number of samples of size 40 and compute the sample slopes, then 30\% of them will be larger than our sample slope of 0.1. The proportion of the shaded area is what we call a \textit{one-sided} $p$-value. We call it one-sided, because we only look at one side of the $t$-distribution: we only look at values that are larger than our $T$-value of 0.53.

We conclude that a slope value of 0.1 is not that strange to find if the population slope is 0. By the same token, it would also have been probable to find a slope of -0.1, corresponding to a $T$-value of -0.53. Since the $t$-distribution is symmetrical, the probability of finding a $T$-value of less than -0.53 is depicted in Figure \ref{fig:inf_18}, and of course this probability is also 0.3.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in ggplot(): could not find function "{}ggplot"{}}}\end{kframe}
\end{knitrout}

Remember that the null-hypothesis is that the population slope is 0, and the alternative hypothesis is that the population slope is \textit{not} 0. We should therefore conclude that if we find a very large positive \textit{or} negative slope, large in the sense of the number of standard errors away from 0, that the null-hypothesis is unlikely to be true. Therefore, if we find a slope of 0.1 or -0.1, then we should determine the probability of finding a $T$-value that is larger than 0.53 or smaller than -0.53. This probability is depicted in Figure \ref{fig:inf_19} and is equal to twice the one-side $p$-value, $2 \times 0.2995977=0.5991953$.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in ggplot(): could not find function "{}ggplot"{}}}\end{kframe}
\end{knitrout}

This probability is called the \textit{two-sided} $p$-value. This is the one that should always be used, since the alternative hypothesis is also two-sided: the population slope can be positive or negative. The question now is: is a sample slope of 0.1 enough evidence to reject the null-hypothesis? To determine that, we determine how many standard errors away from 0 the sample slope is and we look up in tables how often that happens. Thus in our case, we found a slope that is 0.53 standard errors away from 0 and the tables told us that the probability of finding a slope that is at least 0.53 standard errors away from 0 (positive or negative) is equal to 0.5991953. We find this probability rather large, so we decide that we \textit{do not reject the null-hypothesis}.


\section{Hypothesis testing}

In the previous section, we found a one-sided $p$-value of 0.00000294 for a sample slope of -1 and more or less concluded that this probability was rather small. The two-sided $p$-value would be twice this value, so 0.00000588, which is still very small. Next, we determined the $p$-value associated with a slope of 0.1 and found a $p$-value of 0.60. This probability we found was rather large, and we decided not to reject the null-hypothesis. In other words, the probability was so large that we thought that the hypothesis that the population slope is 0 should not be rejected based on our findings.

When should we think the $p$-value is small enough to conclude that the null-hypothesis can be rejected? When can we conclude that the hypothesis that the population slope is 0 is not supported by our sample data? This was a question posed to the founding father of statistical hypothesis testing, Sir Ronald Fischer. In his book \textit{Statistical Methods for Research Workers} (1925), Fisher proposed a probability of 5\%. He advocated 5\% as a standard level for concluding that there is evidence against the null-hypothesis. However, he did not see it as an absolute rule: "If P is between .1 and .9 there is certainly no reason to suspect the hypothesis tested. If it is below .02 it is strongly indicated that the hypothesis fails to account for the whole of the facts. We shall not often be astray if we draw a conventional line at .05...". So Fisher saw the $p$-value as an informal index to be used as a measure of discrepancy between the data and the null-hypothesis: The null-hypothesis is never proved, but is possibly disproved.


Later, Jerzy Neyman and Egon Pearson saw the $p$-value as an instrument in decision making: is the null-hypothesis true, or is the alternative hypothesis true? You either reject the null-hypothesis or you don't, there is nothing in between. A slightly milder view is that you either decide that there is enough empirical evidence to reject the null-hypothesis, or there is not enough empirical evidence to reject the null-hypothesis (not necessarily accepting $H_0$ as true!). This view to data-analysis is rather popular in the social and behavioural sciences, but also in particle physics. In order to make such black-and-white decisions, you decide before-hand, that is, before collecting data, what \textit{level of significance} you choose for your $p$-value to decide whether to reject the null-hypothesis. For example, as your significance level, you might want to choose 1\%. Let's call this chosen significance level $\alpha$. Then you collect your data, you apply your linear model to the data, and find that the $p$-value associated with the slope equals $p$. If this $p$ is smaller than or equal to $\alpha$ you \textit{reject the null-hypothesis}, and if $p$ is larger than $\alpha$ then you \textit{do not reject the null-hypothesis}. A slope with a $p \leq \alpha$ is said to be \textit{significant}, and a slope with a $p > \alpha$ is said to be \textit{non-significant}. If the slope is significant, then one should reject the null-hypothesis and say there is a slope in the population different from zero. If the slope is not significant, then one should not reject the null-hypothesis and say there is no slope in the population (i.e., the slope is 0). Alternatively, one could say there is no empirical evidence for the existence of a slope (this leaves the possibility that there is a slope in the population but that our method of research failed to find one).



\subsection{Exercises}

\begin{enumerate}

\item Suppose you test the null-hypothesis that in a linear equation describing the relationship between the mass of a planet and its volume, the slope equals 0:

\begin{equation}
mass = \beta_0 + \beta_1 volume + \epsilon
\end{equation}

State the null-hypothesis.


\item You set your significance level to 1\%, so $\alpha=0.01$. Next, you measure 52 planets and you find a sample slope of $b_1=6$, with a standard error of 2.24. Determine the $T$-statistic with which you test the null-hypothesis.

\item Determine the two-sided $p$-value on the basis of Table \ref{tab:nonparmixed_4}.

\item What does this $p$-value represent? 

\item Do you reject or do you not reject the null-hypothesis? What does this mean?

\item A car manufacturer wants to build safe cars. One of the engineers conducts collision experiments: cars with a certain velocity are directed towards a parked car. Both the velocity and the deepness of the dent in the parked car is measured. She expects to see that high velocity creates deeper dents and she applies a regression model.

\begin{equation}
deepness = \beta_0 + \beta_1 velocity + \epsilon
\end{equation}

State the null-hypothesis.

\item The engineer sets her significance level to 5\%, so $\alpha=0.05$. Next, she measures 4 cars with speeds between 90 mph and 92 mph and she finds a sample slope of $b_1=2$, with a standard error of 1.5. Determine the $T$-statistic with which you test the null-hypothesis.

\item For her $T$-statistic with 2 degrees of freedom, she finds a two-sided $p$-value of $0.3140057$. Is the effect of velocity on deepness of the dent significant?

\item Should the engineer reject or not reject the null-hypothesis? What does this mean?

\item Could you think of possible reasons why the engineer does not find an effect of velocity on the deepness of the dent?

\end{enumerate}


\subsection{Answers}

\begin{enumerate}

\item

\begin{equation}
H_0: \beta_1 = 0
\end{equation}



\item $T= \frac{6 - 0}{2.24}= 2.68 $

\item

Degrees of freedom is $52-2=50$. From the table for a $t$-distribution with 50 degrees of freedom, we see that a $T$-value of 2.68 is the 0.995th quantile. Thus, half a percent of the $T$-values are larger than 2.68. Because of symmetry, half a percent of the $T$-values is smaller than -2.68. So in total, 1\% of the $T$-values are at least 2.68 away from the mean (both directions). Therefore, the two-sided $p$-value is 0.01.

\item This is the probability that, given that the null-hypothesis is true, we find a sample slope of 6 or larger or a sample slope of -6 or smaller.

\item Our $p$-value of 0.01 is equal to our $\alpha$ and we therefore reject the null-hypothesis. This means that we conclude that the slope coefficient in all planets in the universe is not 0. There is a relationship between the volume of a planet and its mass.

\item

\begin{equation}
H_0: \beta_1= 0
\end{equation}

\item
$T= (2-0)/1.5=2/1.5=1.33$

\item
The $p$-value $0.3140057$ is larger than her $\alpha$, so the effect of velocity is not significant.

\item
 The effect is not significant so she should not reject the null-hypothesis. This means that the conclusion is that there is no relationship between the velocity of the incoming car and the deepness of the dent in the receiving car.

\item First of all, there were only 4 cars tested. A small sample size results in a relatively large standard error, so a relatively small $T$-statistic. The higher the $T$-value the lower the $p$-value. Second, there was hardly any variation in the speed of the incoming car: if you want to find an effect, there should be cars with both high and low velocities, otherwise you won't see any differences in the dents.

\end{enumerate}







\section{Type I and Type II errors in decision making}


Since data-analysis is about probabilities, there is always a chance that you make the wrong decision: you can wrongfully reject the null-hypothesis, or you can wrongfully fail to reject the null-hypothesis. Pearson and Neyman distinguished between two kinds of error: one could reject the null-hypothesis while it is actually true (error of the first kind, or type I error) and one could accept the null-hypothesis while it is not true (error of the second kind, or type II error). Table \ref{tab:typeIandII} gives an overview.


\begin{table}[ht]
\caption{Four different scenarios for hypothesis tests.}
\centering
\begin{tabular}{l l c c}
& & \multicolumn{2}{c}{\textbf{Test conclusion}} \\
  \cline{3-4}
\vspace{-3.7mm} \\
& & do not reject $H_0$ &  reject $H_0$\\
  \cline{2-4}
\vspace{-3.7mm} \\
& $H_0$ true & OK &  Type~I Error \\
\raisebox{1.5ex}{\textbf{Truth}} & $H_A$ true & Type~II Error & OK \\
  \cline{2-4}
\end{tabular}
\label{tab:typeIandII}
\end{table}

To illustrate the difference between type I and type II errors, let's recall the famous fable by Aesop about the boy who cried wolf. The tale concerns a shepherd boy who repeatedly tricks other people into thinking a wolf is attacking his flock of sheep. The first time he cries "There is a wolf!", the men working in an adjoining field come to help him. But when they repeatedly find there is no wolf to be seen, they realise they are being fooled by the boy. One day, when a wolf \textit{does} appear and the boy again calls for help, the men believe that it is another false alarm and the sheep are eaten by the wolf.

In this fable, we can think of the null-hypothesis as the hypothesis that there is no wolf. The alternative hypothesis is that there is a wolf. Now, when the boy cries wolf the first time, there is in fact no wolf. The men from the adjoining field make a type I error: they think there is a wolf while there isn't. Later, when they are fed up with the annoying shepherd boy, they don't react when the boy cries "There is a wolf!". Now they make a type II error: they think there is no wolf, while there actually is a wolf. See Table \ref{fig:Aesop} for the overview.

\begin{table}[ht]
\centering
\begin{tabular}{l l c c}
& & \multicolumn{2}{c}{\textbf{Men in the field}} \\
  \cline{3-4}
\vspace{-3.7mm} \\
& & Think there is no wolf  &  Think there is a wolf \\
  \cline{2-4}
\vspace{-3.7mm} \\
& There is no wolf & OK &  waste of time and energy \\
\raisebox{1.5ex}{\textbf{Truth}} & There is a wolf & devoured sheep & OK \\
  \cline{2-4}
\end{tabular}
\caption{Four different scenarios for wolves and men working in the field.}
\label{fig:Aesop}
\end{table}





Let's return to regression analysis. Suppose you want to determine the slope for the effect of age on height in children. Let the slope now stand for the slope: either there is no slope (no wolf, $H_0$) or there is a slope (wolf, $H_A$). The null-hypothesis is that the slope is 0 in the population of all children (a slope of 0 means there is no slope) and the alternative hypothesis that the slope is not 0, so there is a slope. You might study a sample of children and you might find a certain slope. You might decide that if the $p$-value is lower than a critical value you conclude that the null-hypothesis is not true. Suppose you think a probability of 10\% is small enough to reject the null-hypothesis as true. In other words, if $p \leq 0.10$ then we no longer think 0 is a reasonable value for the population slope. In this case, we have fixed our $\alpha$ or type I error rate to be $\alpha=0.10$. This means that if we study a random sample of children, we look at the slope and find a $p$-value of 0.11, then we do not reject the null-hypothesis. If we find a $p$-value of 0.10, then we reject the null-hypothesis.


Note that the probability of a type I error is the same as our $\alpha$ for the significance level. Suppose we set our $\alpha=0.05$. Then for any $p$-value equal or smaller than 0.05, we reject the null-hypothesis. Suppose the null-hypothesis is true, how often do we then find a $p$-value smaller than 0.05? We find a $p$-value smaller than 0.05 if we find a $T$-value that is above a certain threshold. For instance, for the $t$-distribution with 198 degrees of freedom, the critical value is $\pm 1.97$, \textit{because only in 5\% of the cases we find a $T$-value of $\pm 1.97$ or more if the null-hypothesis is true}! Thus, if the null-hypothesis is true, we see a $T$-value of at least $\pm 1.97$ in 5\% of the cases. Therefore, we see a significant $p$-value in 5\% of the cases if the null-hypothesis is true. This is exactly the definition of a Type I error: the probability that we reject the null-hypothesis (finding a significant $p$-value), given that the null-hypothesis is true. So we call our $\alpha$-value the type I error rate.




Suppose 100 researchers are studying a particular slope. Unbeknownst to them, the population slope is exactly 0. They each draw a random sample from the population and test whether their sample slope is significantly different from 0. Suppose they all use different sample sizes, but they all use the same $\alpha$ of 0.05. Then we can expect that about 5 researchers will reject the null-hypothesis (finding a $p$-value less than or smaller than 0.05) and about 95 will not reject the null-hypothesis (finding a $p$-value of more than 0.05).

Fixing the type I error rate should always be done \textit{before} data collection. How willing are you to take a risk of a type I error? You are free to make a choice about $\alpha$, as long as you report it.

If $\alpha$ represents the probability of making a type I error, then we can use $\beta$ to represent the probability of not rejecting the null-hypothesis while it is not true (type II error, thinking there is no wolf while there is). However, setting the $\beta$ value prior to data collection is a bit trickier than choosing your $\alpha$. It is not possible to compute the probability that we find a non-significant effect $(p > \alpha)$, given that the alternative hypothesis is true, because the alternative hypothesis is only saying that the slope is not equal to 0. In order to compute $\beta$, we need to think first of a reasonable size of the slope that we expect. For example, suppose we believe that a slope of 1 is quite reasonable, given what we know about growth in children. Let that be our alternative hypothesis:


\begin{eqnarray}
H_0: \beta_1 =0 \nonumber \\
H_A: \beta_1 = 1\nonumber
\end{eqnarray}


Next, we determine the distribution of sample slopes under the assumption that the population slope is 1. We know that this distribution has a mean of 1 and a standard deviation equal to the standard error. We also know it has the shape of a $t$-distribution, see Chapter \ref{chap:confidence}. Let sample size be equal to 102 and the standard error 2. If we standardize the slopes by dividing by the standard error, we get the two $t$-distributions in Figure \ref{fig:inf_20}: one distribution of $T$-values if the population slope is 0 (centered around T=0), and one distribution of $T$-values if the population slope is 1 (centered around $T=1/2=0.5$.

Let's fix $\alpha$ to 10\%. The shaded areas represent the area where $p \leq \alpha$: for all values of $T$ smaller than $-1.6859545$ and larger than $1.6859545$, we reject the null-hypothesis. The probability that this happens, \textit{if the null-hypothesis is true}, is equal to $\alpha$ which is 0.10 in this example. The probability that this happens \textit{if the alternative hypothesis is true} (i.e., population slope is 1), is depicted in Figure \ref{fig:inf_21}.


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in ggplot(): could not find function "{}ggplot"{}}}\end{kframe}
\end{knitrout}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in ggplot(): could not find function "{}ggplot"{}}}\end{kframe}
\end{knitrout}

The shaded area in Figure \ref{fig:inf_21} turns out to be $0.1415543$. This represents the probability that we find a significant effect, \textit{if the population slope is 1}. This is actually the \textit{complement}\footnote{Explaination complement.....} of the probability to find a \textit{non}-significant effect, \textit{if the population slope is 1}, which is defined as $\beta$. Therefore, the shaded area in Figure \ref{fig:inf_21} represents $1- \beta$: the probability of finding a significant $p$-value, if the population slope is 1. In this example, $1-\beta$ is equal to $0.1415543$, so $\beta$ is equal to its complement, $1- 0.1415543 = 0.8584457$.

In sum, in this example with an $\alpha$ of 0.10 and assuming a population slope of 1, we find that the probability of a type II error is 0.86: if there is a slope of 1, then we have a 86\% chance of wrongly concluding that the slope is 0.

Type I and II error rates $\alpha$ and $\beta$ are closely related. If we feel that a significance level of $\alpha=0.10$ is too high, we could choose a level of 0.01. This ensures that we are less likely to reject the null-hypothesis when it is true. The critical value for our $T$-statistic is then equal to $\pm  2.6258905$, see Figure \ref{fig:inf_22}. In Figure \ref{fig:inf_23} we see that if we change $\alpha$, we also get a different value for $1-\beta$, in this case $0.0196567$.

Table \ref{fig:probs} gives an overview of how $\alpha$ and $\beta$ are related to type I and type II error rates. If a $p$-value for a statistical test is equal to or smaller than a pre-chosen significance level $\alpha$, the probability of a type I error equals $\alpha$. The probability of a type II error rate is equal to $\beta$. 

\begin{table}[ht]
\centering
\begin{tabular}{l l c c}
& & \multicolumn{2}{c}{\textbf{Statistical outcome}} \\
  \cline{3-4}
\vspace{-3.7mm} \\
& & $p > \alpha$  &  $p \leq \alpha$ \\
  \cline{2-4}
\vspace{-3.7mm} \\
& $H_0$ & $1-\alpha$ &  $\alpha$ \\
\raisebox{1.5ex}{\textbf{Truth}} & $H_A$  & $\beta$ & $1-\beta$ \\
  \cline{2-4}
\end{tabular}
\caption{The probabilities of a statistical outcome under the null-hypothesis and the alternative hypothesis.}
\label{fig:probs}
\end{table}


Thus, if we use smaller values for $\alpha$, we get smaller values for $1-\beta$, so we get larger values for $\beta$. This means that if we lower the probability of rejecting the null-hypothesis given that it is true (type I error) by choosing a lower value for $\alpha$, we inadvertently increase the probability of failing to reject the null-hypothesis given that it is not true (type II error). 

Think again about the problem of the sheep and the wolf. Instead of the boy, the men could choose to put a very nervous person on watch, someone very scared of wolves. With the faintest hint of a wolf's presence, the man will call out "Wolf!". However, this will lead to many false alarms (type I errors), but the men will be very sure that when there actually is a wolf, they will be warned. Alternatively, they could choose to put a man on watch that is very laid back, very relaxed, but perhaps prone to nod off. This will lower the risk of false alarms immensely (no more type I errors) but it will dramatically increase the risk of a type II error!

One should therefore always strike a balance between the two types of errors. One should consider how bad it is to think that the slope is not 0 while it is, and how bad it is to think that the slope is 0, while it is not. If you feel that the first mistake is worse than the second one, then make sure $\alpha$ is really small, and if you feel that the second mistake is worse, then make $\alpha$ not too small. Another option, and a better one, to avoid type II errors, is to increase sample size, as we will see in the next section.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in ggplot(): could not find function "{}ggplot"{}}}\end{kframe}
\end{knitrout}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in ggplot(): could not find function "{}ggplot"{}}}\end{kframe}
\end{knitrout}


\subsection{Exercises}

\begin{enumerate}

\item When we talk about decision making in data analysis, what do we mean by $\beta$?

\item What do we mean by $1-\beta$?

\item What doe we mean by $\alpha$?

\item What do we mean by making a type I error?

\item What do we mean by making a type II error?

\item What do we mean by $1-\alpha$?


\end{enumerate}



Answers:

\begin{enumerate}

\item The type II error rate, or the probability of not rejecting the null-hypothesis while the null-hypothesis is not true.

\item The probability of finding a significant effect if the alternative hypothesis is true.

\item The type I error rate, or the probability of rejecting while the null-hypothesis is true

\item Wrongly concluding that the null-hypothesis is not true.

\item Wrongly concluding that the null-hypothesis is true.

\item The probability of not rejecting the null-hypothesis while the null-hypothesis is true.


\end{enumerate}


\section{Statistical power}

Null-hypothesis testing only involves the null-hypothesis: we look at the sample slope, compute the $T$-statistic and then see how often such a $T$-value and larger values occur given that the population slope is 0. Then we look at the $p$-value and if that $p$-value is smaller than or equal to $\alpha$, we reject the null-hypothesis. Therefore, null-hypothesis testing does not involve testing the alternative hypothesis. We can decide what value we choose for our $\alpha$, but not our $\beta$. The $\beta$ is dependent on what the actual population slope is, and we simply don't know that.

As stated in the previous section, we can compute $\beta$ only if we have a more specific idea of an alternative value for the population slope. We saw that we needed to think of a reasonable value for the population slope that we might be interested in. Suppose we have the intuition that a slope of 1 could well be the case. Then, we would like to find a $p$-value of less than $\alpha$ if indeed the slope were 1. We hope that the probability that this happens is very high: the conditional probability that we find a $T$-value large enough to reject the null-hypothesis, given that the population slope is 1. This probability is actually the \textit{complement} of $\beta$, $1-\beta$: the probability that we reject the null-hypothesis, given that the alternative hypothesis is true. This $1-\beta$ is often called the \textit{statistical power} of a null-hypothesis test. When we think again about the boy who cried wolf: the power is the probability that the men think there is a wolf if there is indeed a wolf. The power of a test should always be high: if there is a population slope that is not 0, then of course you would like to detect it by finding a significant $T$-value!

In order to get a large value for $1-\beta$, we should have large $T$-values in our data-analysis. There are two ways in which we can increase the value of the $T$-statistic. Since with null-hypothesis testing $T=(b-0)/se=b/se$, we can get large values for $T$ if 1) we have a small standard error, $se$, or 2) if we have a large value for $b$. 


Let's first look at the first option: a small standard error. We get a small standard error if we have a large sample size, see Section \ref{sec:sampsizese}. If we go back to the example of the previous section where we had a sample size of 102 children and our alternative hypothesis was that the population slope was 1, we found that the $t$-distribution for the alternative hypothesis was centered around 0.5, because the standard error was 2. Suppose that we would increase sample size to 1200 children, then our standard error might be 0.2. Then our $t$-distribution for the alternative hypothesis is centerd at 5. This is shown in Figure \ref{fig:inf_24}.




\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in ggplot(): could not find function "{}ggplot"{}}}\end{kframe}
\end{knitrout}


We see from the shaded area that if the population slope is really 1, there is a very high chance that the $T$-value for the sample slope will be larger than 2.58, the cutoff point for an $\alpha$ of 0.01 and 1198 degrees of freedom. The probability of rejecting the null-hypothesis while it is not true, is therefore very large. This is our $1-\beta$ and we call this the power of the null-hypothesis test. We see that with increasing sample size, the power to find a significant $T$-value increases too.

Now let us look at the second option, a large value of $b$. Sample slope $b$ depends of course on the population slope $\beta$. The power becomes larger when the population slope is further away from zero. If the population slope were 10, and we only had a sample of 102 children (resulting in a standard error of 2), the $t$-distribution for the alternative hypothesis that the population slope is centered around $B/se=10/2=5$, resulting in the same plot as in Figure \ref{fig:inf_24}, with a large value for $1-\beta$. Unfortunately, the population slope is beyond our control: the population slope is a given fact that we cannot change. The only thing we can change most of the times is sample size. 

In sum: the statistical power of a test is the probability that the null-hypothesis is rejected, given that it is not true. This probability is equal to $1-\beta$. The statistical power of a test increases with sample size, and depends on the actual population slope. The further away the population slope is from 0 (positive or negative), the larger the statistical power. Earlier we also saw that $1-\beta$ decreases with increasing $\alpha$: the smaller $\alpha$, the lower the power.


\subsection{Exercises}


\begin{enumerate}

\item Prior to an experiment with 100 participants, a researcher fixes $\alpha$ to 0.05. She expects to find a slope of at least 2. She then computes the power of the test and finds 0.50. What does this mean?

\item She would like to increase the power of her test, but is unable to increase sample size due to financial constraints. What can she do?


\end{enumerate}


Answers:

\begin{enumerate}

\item A power of 0.50 means that if the alternative hypothesis is true (i.e. the slope is 2), then the probability of finding a significant $p$-value ($p \leq 0.05$) is 0.50.

\item She can't change sample size, nor can she change the population slope. She can only change her $\alpha$. The lower the $\alpha$, the lower the power. She could therefore use a higher $\alpha$, for instance 0.10. However, this of course raises the probability of a type I error.


\end{enumerate}


\section{Power analysis}
Because of these relationships between statistical power, $\alpha$, sample size and the actual population slope, we can compute the statistical power for any combination of $\alpha$, sample size and hypothetical population slope.


If you really care about the quality of your research, you carry out a \textit{power analysis} prior to collecting data. With such an analysis you can find out how large your sample size should be. You can find many tools online that can help you with that.

Suppose you want to minimize the probability of a type I error, so you choose an $\alpha=0.01$. Next, you think of what kind of population slope you would like to find, if it indeed has that value. You could perhaps base this expectation on earlier research. Suppose that you feel that if the population slope is 0.15, you would really like to find a significant $T$-value so that you can reject the null-hypothesis. Next, you have to specify how badly you want to reject the null-hypothesis if indeed the population slope is 0.15. If the population slope is really 0.15, then you would like to have a high probability to find a $T$-value large enough to reject the null-hypothesis. This is of course the power of the test, $1-\beta$. Let's say you want to have a power of 0.90. Now you have enough information to calculate how large your sample size should be.

Let's look at G*power\footnote{http://www.gpower.hhu.de/}, an application that can be downloaded from the web. If we start the app, we can ask for the sample size required for a slope of 0.15, an $\alpha$ of 0.01, a power ($1-\beta$) of 0.90. Let the standard deviation of our dependent variable (y=height) be 3 and the standard deviation of our independent variable (x=age) be 2. Then we get the input as displayed in Figure \ref{fig:gpower}. Note that you should use two-sided $p$-values, so tails=two. From the output we see that the required sample size is 1477 children.


\begin{figure}[h]
    \begin{center}
       \includegraphics[scale=0.4,trim={0cm 0cm 0cm 1cm}, clip]{"/Users/stephanievandenberg/SURFdrive/Werk/Onderwijs/statistiek/book/linear models/book/gpower".png}
    \end{center}
    \caption{G*power output for a simple regression analysis.}
    \label{fig:gpower}
\end{figure}



\subsection{Exercises}


\begin{enumerate}

\item You want to predict height by age in children. Use G*power to find out how large sample size should be if you want to find a slope of 0.15 with a type I error rate of 0.01, and a power of 80\%. Suppose the standard deviation of height is about 3 and the standard deviation of age is about 2.

\item A teacher friend says you can use her children, all having the age of 9. The standard deviation for age in a classroom of 9-year-olds is about 0.5, and their heights have a standard deviation of about 1. How many children of age 9 would you need in order to get your power of 80\%?

\item A hockey friend says you can use children from his hockey club. They have ages between 5 and 15, and the standard deviation is about 2. The standard deviation of their heights is about 0.5. How many hockey club children would you need for your power of 80\%?

\item Explain why you need so many children from age 9, and fewer children with ages between 5 and 15. Sketch a scatterplot, if that helps you.


\end{enumerate}


Answers:
\begin{enumerate}

\item 1160 children.

\item 2068 children.

\item 25 children.


\item See Figure \ref{fig:bla}. In order to see a relationship between variation in variable $x$ and variable $y$, there should at least be variation in one of them. So if you want to see an effect, make sure you see a lot of variation in one the two variables, for instance use a sample with a large spread in age.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in ggplot(data.frame(age, height), aes(age, height)): could not find function "{}ggplot"{}}}\end{kframe}
\end{knitrout}




\end{enumerate}


\section{Criticism on null-hypothesis testing and $p$-values}

The practice of null-hypothesis significance testing (NHST) is widespread. However, from the beginning it has received much criticism. One of the first to critize the approach was the inventor of the $p$-value, Sir Ronald Fisher himself. Fisher explicitly contrasted the use of the $p$-value for statistical inference in science with the Pearson-Neyman approach, which he termed "Acceptance Procedures". Whereas in the Pearson-Neyman approach the only relevance of the $p$-value is whether it is smaller or larger than the fixed significance level $\alpha$, Fisher emphasized that the exact $p$-value should be reported to indicate the strength of evidence against the null-hypothesis. He emphasized that no single $p$-value can refute a hypothesis, since chance always allows for type I and type II errors. Conclusions can and will be revised with further experimentation; science requires more than one study to reach solid conclusions. Decision procedures with clear-cut decisions based on one study only hamper science and lead to tunnel-vision.

Apart from these science-theoretical considerations of the NHST, there are also practical reasons why pure NHST should be avoided. In at least a number of research fields, the $p$-value has become more than just the criterion for finding an effect or not: it has become the criterion of whether the research is publishable or not. Editors and reviewers of scientific journals have increasingly interpreted a study with a significant effect to be more interesting than a study with a non-significant effect. For that reason, in scientific journals you will find mostly studies reported with a significant effect. This has led to \textit{the file-drawer problem}: the literature reports significant effects for a particular phenomenon, but there can be many unpublished studies with non-significant effects for the same phenomenon. These unpublished studies remain unseen in file-drawers (or these days on hard-drives). So based on the literature there might seem to exist a particular phenomenon, but if you would put all the results together, including the unpublished studies, the effect might disappear completely.

Remember that if the null-hypothesis is true and everyone uses an $\alpha$ of 0.05, then out of 100 studies of the same phenomenon, only 5 studies will be significant and are likely to be published. The remaining 95 studies with insignificant effects are more likely to remain invisible. 

As a result of this bias in publication, scientists who want to publish their results are tempted to fiddle around a bit more with their data in order to get a significant result. Or if they obtain a $p$-value of 0.07, they decide to increase their sample size, and perhaps stop as soon as the $p$-value is 0.05 or less. This horrible malpractice is called \textit{$p$-hacking} and is extremely harmful to science. As we saw earlier, if you want to find an effect and not miss it, you should carry out a power analysis \textit{before} you collect the data and make sure that your sample size is large enough to obtain the power you want to have. Increasing sample size \textit{after} you have found a non-significant  increases your type I error rate dramatically: if you stop collecting data \textit{until} you find a significant $p$-value, the type I error rate is equal to 1!

There have been wide discussions the last few years about the use and interpretation of $p$-values. In a formal statement, the American Statistical Association published six principles that should be well understood by anyone, including you, who uses them.


The six principles are:

\begin{enumerate}

\item
$P$-values can indicate how incompatible the data are with a specified statistical model (usually the null-hypothesis).
\item
$P$-values \textit{do not} measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Instead, they measure how likely it is to find a sample slope of at least the size that you found, given that the population slope is 0.
\item
Scientific conclusions and business or policy decisions should not be based only on whether a $p$-value passes a specific threshold. For instance, also look at the size of the effect: is the slope large enough to make policy changes worth the effort? Have other studies found effects of similar sizes?
\item
Proper inference requires full reporting and transparency. Always report your sample slope, the standard error, the $T$-statistic, the degrees of freedom, and the $p$-value. Only report about null-hypotheses that your study was designed to test.
\item
A $p$-value or statistical significance \textit{does not} measure the size of an effect or the importance of a result. (See principle 1)
\item
By itself, a $p$-value does not provide a good measure of evidence regarding a model or hypothesis. At least as important is the design of the study.
\end{enumerate}

These six principles are further explained in the statement online{\footnote{https://amstat.tandfonline.com/doi/abs/10.1080/00031305.2016.1154108}}. The bottom line is, $p$-values have worth but only when used and interpreted in a proper way, although some disagree. The philosopher of science William Rozeboom once called NHST surely the most bone-headedly misguided procedure ever institutionalized in the rote training of science students. The scientific journal \textit{Basic and Applied Social Psychology} even banned NHST altogether: $T$-values and $p$-values are not allowed if you want to publish your research in that journal.

Most researchers now realize that reporting confidence intervals is often a lot more meaningful than reporting whether a $p$-value is significant or not. A $p$-value only says something about evidence against the hypothesis that the slope is 0. In contrast, a confidence interval gives a whole range of reasonable values for the population slope. If 0 lies within the confidence interval, then 0 is a reasonable value; if it is not, then 0 is not a reasonable value so that we can reject the null-hypothesis.

Using confidence intervals also counters one fundamental problem of null-hypotheses: nobody believes in them! Remember that the null-hypothesis states that a particular effect (a slope) is exactly 0: not 0.0000001, not -0.000201, but exactly 0.000000000000000000000.

Sometimes a null-hypothesis doesn't make sense at all. Suppose we are interested to know what the relationship is between age and height in children. Nobody believes that the effect of age on height is 0. Why then test this hypothesis? More interesting would be to know \textit{how large} the population slope is. A confidence interval would then be much more informative than a simple rejection of the null-hypothesis.

In some cases, a null-hypothesis can be slightly more meaningful: suppose you are interested in the effect of cognitive behavioural therapy on depression. You hope that the number of therapy sessions has a negative effect on the severity of the depression, but it is entirely possible that the effect is very close to nonexisting. Of course you can only look at a sample of patients and determine the sample slope. But think now about the population slope: think about all patients in the world with depression that theoretically could partake in the research. Some of them have 0 sessions, some have 1 session, and so on. Now imagine that there are 1 million of such people. How likely is it that in the population, the slope for the regression is exactly 0? Not 0.00000001, not -0.0000000002, but exactly 0.0000000000. Of course, this is extremely unlikely. The really interesting question in such research is whether there is a \textit{meaningful} effect of therapy. For instance, an effect of at least half a point decrease on the Hamilton depression scale for 5 sessions. Also in this case, a confidence interval for the effect of therapy on depression would be more helpful than a simple $p$-value. A confidence interval of -2.30 to -0.01 says that a small population effect of -0.01 might be there, but that an effect of -0.0001 or 0.0000 is rather unlikely. The $p$-value less than $\alpha$ only tells you only that a value of exactly 0.0000 is not realistic.


% In its turn, the $p$-value, as we have seen, depends on the $T$-statistic and the degrees of freedom. The degrees of freedom in turn depends on sample size. The $T$-statistic also depends on sample size, as it is partly based on the standard error.
%
% If the alternative hypothesis is true, that is, if the population slope is not 0, then the probability of getting a $p$-value larger than 0.1, is equal to $\beta$. This is because by definition $\beta$ is the probablity of a type II error: the error that we \textit{do not reject the null-hypothesis, while the null-hypothesis is not true}. For example, suppose the population slope is 0.01. In a sample we find a slope of 1, with a $T$-statistic of 2.50 with 45 degrees of freedom. The associated $p$-value is equal to $round(2*pt(-2.5,45),3)$. If $\alpha=0.01$ then we conclude that this slope of 1 is not significantly different from zero. However, since the population slope is actually different from 0, namely 0.01, we draw the wrong conclusion. The conditional probability\footnote{$\alpha$, $\beta$ and the $p$-value are conditional probabilities. For the distinction between a probability and a conditional probability, see \dots. In short, suppose that in the whole world, 51\% of the people are at most 17 years old. However, suppose that in the Netherlands that proportion is only 20\%. Then if we pick a random person, the probability that that person is at most 17 years old is 0.51. However, if we happen to know that the person was picked from the Dutch population, then we know better: we know that the probability has decreased to 20\%. Thus the conditional probablity that a person is under age, given that the person is Dutch, equals 0.20. The conditional probabiilty that a person is under age, given that the person is \textit{not} Dutch, equals more than 0.51.} that we find a non-significant slope (we reject the null-hypothesis), given that the population slope differs from 0 (the null-hypothesis is not true) is equal to $\beta$.
%
%
% Of course we'd like to have a small $\beta$: we don't like making mistakes. So if indeed the null-hypothesis is false, we want the probability that we reject the null-hypothesis as large as possible. In order to achieve that, we need to have a $T$-value as large as possible. Since $T=b/se$, this can be achieved by having a standard error as small as possible, and this happens when our sample size is as large as possible.
%


%%%%%%%%%%



So, instead of asking research questions like "Is there a linear relationship between x and y?" you might ask: "How large is the linear effect of x on y?" Instead of a question like "Is there an effect of the intervention?" it might be more interesting to ask: "How large is the effect of the intervention?"

Summarizing, remember the following principles when doing your own research or evaluating the research done by others:

\begin{itemize}

\item Inference about a population slope or intercept can be made on the basis of sample data, but only in probabilistic terms. This means that a simple statement like "the value of the population slope is definitely not zero" cannot be made. Only statements like "A population slope of 0 is not very likely given the sample data" can be made.

\item Science is cumulative. No study is definitive. Effects should be replicated by independent researchers.

\item Always report your regression slope or intercept, with the standard error and the sample size. Based on these, the $T$-statistics can be computed with the degrees of freedom. Then if several other researchers have done the same type of research, the results can be combined in a so-called meta-analysis, so that a stronger statement about the population can be made, based on a larger total sample size. The standard error and sample size moreover allow for the construction of confidence intervals. But better is to report confidence intervals yourself.

\end{itemize}



\subsection{Exercise}

Why is it that the type I error rate becomes 1 if you keep increasing your sample size until the $p$-value is smaller than $\alpha$?


\section{Relationship between $p$-values and confidence intervals}
% We could have also come to the same conclusion using the 95\% confidence interval. If we find a sample slope of 1, and we know that the standard error is equal to 2, then we can find the 95\% confidence interval for the $T$-statistic (0.5) if we use a $t$-distribution with 38 degrees of freedom. From tables we can deduce that with a $t$-distribution of 38 degrees of freeedom, 2.5\% of the area is left of qt(0.025, df=38) and 2.5\% of the area is right of qt(0.975, df=38). This way we know that the confidence interval for the $T$-value is from $1  qt(0.025, df=38)\times 2$ to $1 + qt(0.975, df=38)\times 2$, so from $1+2*qt(0.025, df=38)$ to 1-qt(0.025, df=38)*2.
%
% We see that the value 0 is within this range, so 0 is a reasonable value for the population slope. From this we know that the $p$-value for the null-hypothesis is less than 5\%.
%
% In Figure \ref{fig:inf_25} we see a $T$-value of 0.5 (black line). This $T$-value of 0.5 is not significant at an $\alpha$ of 5\%, because it is not in the shaded tails of the $t$-distribution. These shaded tails represent the most extreme 5\% of the possible $T$-values. These shaded tails start at qt(0.025, df=38) and qt(0.975, df=38). The red lines represent the 95\% confidence interval for the population $T$-value (the standardized population slope, i.e. $\beta/se$). This confidence interval stretches from $0.5  qt(0.025, df=38)\times 1$ to $0.5 + qt(0.975, df=38)\times 1$ (remember that we're looking at T-values so standardized slopes; therefore the standard deviation is 1). Thus, the confidence interval ranges from $0.5 + qt(0.025, df=38)$ to $0.5 + qt(0.975, df=38)$. The value 0 lies within this interval. It is therefore one of the values that could be the $T$-value of the population slope. If the T-value is 0, then the population slope itself is also zero: $T=0=\beta/se; \beta=0$. Thus, 0 is a realistic value for the population slope.
%
% In Figure \ref{fig:inf_26} we see a $T$-value of qt(0.98, df=38) (black line). This $T$-value of qt(0.98, df=38) is just significant at an $\alpha$ of 5\%, because it is just within one of the shaded tails of the $t$-distribution. These shaded tails start at qt(0.025, df=38) and qt(0.975, df=38). The red lines represent the 95\% confidence interval for the population $T$-value (the standardized population slope, i.e. $\beta/se$). This confidence interval stretches from $qt(0.98, df=38)  qt(0.025, df=38)\times 1$ to $qt(0.98, df=38) + qt(0.975, df=38)\times 1$ (remember that we're looking at T-values so standardized slopes; therefore the standard deviation is 1). Thus, the confidence interval ranges from $qt(0.98, df=38) + qt(0.025, df=38)$ to $qt(0.98, df=38) + qt(0.975, df=38)$. The value 0 lies just outside this interval. It is therefore one of the values that could not be the $T$-value of the population slope. If the T-value is 0, then the population slope itself is also zero: $T=0=\beta/se; \beta=0$. Thus, 0 is not a realistic value for the population slope.
%
% In Figure \ref{fig:inf_27} we see a $T$-value of 0 (black line). This $T$-value of 0 is not significant at an $\alpha$ of 5\%, because it is outside of the shaded tails of the $t$-distribution. The red lines represent the 95\% confidence interval for the population $T$-value (the standardized population slope, i.e. $\beta/se$). This confidence interval stretches from $qt(0.025, df=38)\times 1$ to $qt(0.975, df=38)\times 1$ (remember that we're looking at T-values so standardized slopes; therefore the standard deviation is 1). Thus, the confidence interval ranges from $qt(0.025, df=38)$ to $ qt(0.975, df=38)$. The value 0 lies within this interval. It is therefore one of the values that could not be the $T$-value of the population slope. If the T-value is 0, then the population slope itself is also zero: $T=0=\beta/se; \beta=0$. Thus, 0 is not a realistic value for the population slope.
%
%
%
% <<inf_25,fig.height=4, echo=FALSE, fig.align='center', fig.cap='Relationship between a non-significant T-value (black line) and its confidence interval (red lines).'>>=
%
% df = 38; ncp = 0; limits = c(-5,5)
% lb=-20; ub=-2.02
%     x <- seq(limits[1], limits[2], length.out = 100)
%     xmin <- max(lb, limits[1])
%     xmax <- min(ub, limits[2])
%     areax <- seq(xmin, xmax, length.out = 100)
%     area <- data.frame(x = areax, ymin = 0, ymax = dt(areax, df=df, ncp=ncp))
%     (ggplot()
%      + geom_line(data.frame(x = x, y = dt(x, df=df, ncp=ncp)),
%                  mapping = aes(x = x, y = y))
%      + geom_area(data = area, mapping = aes(x = x,  y = ymax))
%      + scale_x_continuous(limits = limits, breaks=seq(-5,5,1))
%      + geom_area(data = area, mapping = aes(x = seq(2.02, 5, length.out = 100),  y = dt(seq(2.02, 5, length.out = 100), df=df, ncp=ncp)))
%             + geom_vline(xintercept = 0.5)  + xlab("T")
%             +geom_vline(xintercept=(0.5-2.02), col=2) + geom_vline(xintercept=(0.5+2.02), col=2) +ylab("density"))
% @
%
%
% <<inf_26,fig.height=4, echo=FALSE, fig.align='center', fig.cap='Relationship between a significant T-value (black line) and its confidence interval (red lines).'>>=
%
% df = 38; ncp = 0; limits = c(-5,5)
% lb=-20; ub=-2.02
%     x <- seq(limits[1], limits[2], length.out = 100)
%     xmin <- max(lb, limits[1])
%     xmax <- min(ub, limits[2])
%     areax <- seq(xmin, xmax, length.out = 100)
%     area <- data.frame(x = areax, ymin = 0, ymax = dt(areax, df=df, ncp=ncp))
%     (ggplot()
%      + geom_line(data.frame(x = x, y = dt(x, df=df, ncp=ncp)),
%                  mapping = aes(x = x, y = y))
%      + geom_area(data = area, mapping = aes(x = x,  y = ymax))
%      + scale_x_continuous(limits = limits, breaks=seq(-5,5,1))
%      + geom_area(data = area, mapping = aes(x = seq(2.02, 5, length.out = 100),  y = dt(seq(2.02, 5, length.out = 100), df=df, ncp=ncp)))
%             + geom_vline(xintercept = qt(0.98, df=38))  + xlab("T")
%             +geom_vline(xintercept=(qt(0.98, df=38)-2.02), col=2) + geom_vline(xintercept=(qt(0.98, df=38)+2.02), col=2)+ylab("density"))
% @
%
% <<inf_27,fig.height=4, echo=FALSE, fig.align='center', fig.cap='Relationship between a  T-value of 0 (black line) and its confidence interval (red lines).'>>=
%
% df = 38; ncp = 0; limits = c(-5,5)
% lb=-20; ub=-2.02
%     x <- seq(limits[1], limits[2], length.out = 100)
%     xmin <- max(lb, limits[1])
%     xmax <- min(ub, limits[2])
%     areax <- seq(xmin, xmax, length.out = 100)
%     area <- data.frame(x = areax, ymin = 0, ymax = dt(areax, df=df, ncp=ncp))
%     (ggplot()
%      + geom_line(data.frame(x = x, y = dt(x, df=df, ncp=ncp)),
%                  mapping = aes(x = x, y = y))
%      + geom_area(data = area, mapping = aes(x = x,  y = ymax))
%      + scale_x_continuous(limits = limits, breaks=seq(-5,5,1))
%      + geom_area(data = area, mapping = aes(x = seq(2.02, 5, length.out = 100),  y = dt(seq(2.02, 5, length.out = 100), df=df, ncp=ncp)))
%             + geom_vline(xintercept = 0)  + xlab("T")
%             +geom_vline(xintercept=(-2.02), col=2) + geom_vline(xintercept=2.02, col=2)+ylab("density"))
% @
%


In previous sections we stated that if the value 0 lies within a confidence interval, it is a reasonable value for the population slope. If 0 is not within the interval, 0 is not a reasonable value for the population slope, so we have to reject the null-hypothesis. Here we will elaborate a little on this theme.

Both the confidence interval and the $p$-value are based on the same $t$-distribution. Suppose we set our $\alpha$ to 0.05, and our sample size is 102. This means that if we find a $p$-value $p \leq 0.05$ we reject the null-hypothesis that the slope is 0. The $p$-value depends on how many standard deviations our sample slope deviates from 0. We calculate this by computing a standardized slope. For example, for a sample slope of 1 and a standard error of 0.5, our standardized slope is $T=(1-0)/0.5=2$. In other words, our sample slope of 1 is 2 standard errors away from 0. From $t$-tables, we know that with 100 degrees of freedom, the 2.5th and 97.5th percentiles are -1.98 and 1.98, respectively (see Table \ref{tab:table_1}). Therefore, the $p$-value depends on the size of the $T$-statistic. If it is equal to -1.98 or 1.98, the $p$-value is exactly 0.05. If the $T$-statistic is smaller than -1.98 or larger than 1.98, the $p$-value is smaller than 0.05.

The values -1.98 and 1.98 are also used for the construction of the 95\% confidence interval. The lower bound lies at 1.98 times the standard error below the sample slope, and the upper bound lies at 1.98 times above the sample slope. Therefore, if 0 lies more than 1.98 standard erros away from the mean, it lies outside the confidence interval. But if 0 lies more than 1.98 standard erros away from the mean, this implies that the sample slope lies more than -1.98 standard erros away from 0, which corresponds to a $T$-statistic of more than $\pm 1.98$. Thus, if 0 is not within the 95\% confidence interval, we know that the $p$-value is smaller than 0.05.

Using the same reasoning as above, we also know that if 0 is not within the 99\% confidence interval, we know that the $p$-value is smaller than 0.01, and if 0 is not within the 99.9\% confidence interval, we know that the $p$-value is smaller than 0.001, etcetera.

A 95\% confidence interval can therefore also be seen as the range of possible values for the null-hypothesis that cannot be rejected with an $\alpha$ of 5\%. By the same token, a 99\% confidence interval can be seen as the range of possible values for the null-hypothesis that cannot be rejected with an $\alpha$ of 1\%, etcetera.



\section{Inference using SPSS}

Figure \ref{fig:inf_28} shows an example of a regression analysis on 102 datapoints. The dependent variable is $y$ and the independent variable is $x$. The black line represents the linear equation in the population, whereas the blue line represents the sample equation:



\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in data.frame(x, y) \%>\% ggplot(aes(x, y)): could not find function "{}\%>\%"{}}}\end{kframe}
\end{knitrout}

\begin{eqnarray}
Population: &y&= 0 + 0.2 \times x + \epsilon\\
Sample: &y&= 0.15 + 0.18\times x + e
\end{eqnarray}

The syntax that we can use for these sampe data is

\begin{verbatim}
UNIANOVA y WITH x
  /DESIGN=x
  /PRINT=PARAMETER
  /CRITERIA=ALPHA(.01).
\end{verbatim}


Note that we have set the significance level $\alpha$ to 0.01 with the statement \texttt{CRITERIA=ALPHA(0.01)}. Figure \ref{fig:inf_29} shows the SPSS output. Look at the Parameter Estimates table. It shows the intercept, with a standard error of 0.111. The $t$-value in the output is the $T$-statistic for the null-hypothesis, and is equal to $(B-0)/SE=0.15/0.111=1.355$. We had 102 data points, so the degrees of freedom is equal to $102-2=100$. \footnote{Note that this is not shown in the Parameter Estimates table, but in the Tests of Between-Subjects Effects table in the row for Error (error is another word for residual). In that row we see the error degrees of freedom (df) of 100.} From online tables it is known that with 100 degrees of freedom, 0.089 of $t$-values are larger than 1.355 and 0.089 of $t$-values are smaller than -1.355. SPSS knows this and automatically calculates the two-sided $p$-value. Therefore, the two-sided $p$-value for a $T$-statistic of 1.355 with 100 degrees of freedom is equal to $2 \times 0.089 = 0.178$. Since $p > 0.01$, we cannot reject the null-hypothesis that the intercept in the population data is equal to 0. SPSS also shows the 99\% confidence interval that runs from -0.141 to 0.441. All these values in this interval are reasonable values for the population intercept.

Let's now turn to the output for the effect of $x$. The table shows a slope of 0.18 with a standard error of 0.019. Therefore, the $T$-value for the null-hypothesis equals $(0.18-0)/0.02=9.515$. With 100 degrees of freedom, a proportion of 0 of the $t$-values is larger than 9.515 and 0 of the $t$-values is smaller than -9.515. Therefore, the associated $p$-value is 0. Since $p \leq 0.01$, we reject the null-hypothesis that the population slope is 0. The 99\% confidence interval for the population slope is from 0.13 to 0.23.

\begin{figure}[h!]
    \begin{center}
       \includegraphics[scale=0.8,trim={0cm 19cm 0cm 0cm}, clip]{"/Users/stephanievandenberg/Dropbox/Statistiek_Onderwijs/Data Analysis/spss examples linear model/simple regression/inference1a".pdf}
    \end{center}
    \caption{Output for a simple regression analysis.}
    \label{fig:inf_29}
\end{figure}


\subsection{Exercises}

\begin{enumerate}
\item Suppose you want to predict the personality trait aggressiveness on the basis of yearly income in Euros. The variable that measures aggressiveness is \textbf{aggr} and the variable that measures income is \textbf{yearincome}. Give the linear equation for the relationship between these two variables in the population.

\item You want to know whether there is a relationship between income and aggressiveness. State the null-hypothesis in terms of the linear equation you gave.

\item Suppose you want to test this null-hypothesis using a type I error rate of 0.05. Provide the SPSS syntax that is needed to perform this test.

\item Suppose someone else has done the analysis for you using a different software package and gives you the output in Figure \ref{fig:inf_29}. See if you can find the 95\% confidence interval for the effect of yearly income on aggressiveness.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in lm(aggr \textasciitilde{} yearincome) \%>\% summary(): could not find function "{}\%>\%"{}}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in lm(aggr \textasciitilde{} yearincome) \%>\% confint(1, 0.95) \%>\% round(3): could not find function "{}\%>\%"{}}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in lm(aggr \textasciitilde{} yearincome) \%>\% confint(2, 0.95) \%>\% round(3): could not find function "{}\%>\%"{}}}\end{kframe}
\end{knitrout}





