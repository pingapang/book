\chapter{Non-parametric alternatives for linear mixed models}\label{chap:nonpar2}


\section{Checking assumptions}

In previous chapters we discussed the assumptions of linear models and linear mixed models: linearity (in parameters), homoscedasticity (equal variance), normal distribution of residuals, normal distribution of random effects (relevant for linear mixed models only), and independence (no clustering unaccounted for). 




The problem of non-linearity can be solved by introducing quadratic terms, for instance by replacing a linear model $Y = b_0 + b_1 X + e$ by another linear model $Y = b_0 + b_1 X + b_2 X^2 + e$.

If we have non-independence, then you can introduce either an extra fixed effect or a random effect for this clustering. For example, if you see that cars owned by low income families have much more mileage than cars owned by high income families, you can account for this by adding a fixed effect of an income variable as predictor. If you see that average mileage is rather similar within municipality but that average mileage can vary quite a lot across municipalities, you can introduce a random effect for municipality (if you have data say from 30 different municipalities). 

Unequal variance of residuals and non-normal distribution of residuals are harder to tackle. Unequal variance can be tackled sometimes by using linear models, but with more advanced options, or by making corrections to $p$-values that make inference more robust against model violations. Violations of normality are even a bigger problem. Non-normality can sometimes be solved by using generalized linear models (see next chapter). A combination of non-normality and unequal variance can sometimes be solved by using a transformation of the data, for instance not analysing $Y = b_0 + b_1 X + e$ but analysing $log(Y)=  b_0 + b_1 X + e$ or $\sqrt{Y}=  b_0 + b_1 X + e$.

If these data transformations or advanced options don't work (or if you're not acquainted with them), and your data show non-equal variance and/or non-normally distributed residuals, there are non-parametric alternatives.  Here we discuss two: Friedman's test and Wilcoxon's signed rank test. We explain them using an imaginary data set on speed skating.
\\
\\
Suppose we have data on 12 speed skaters that participate on the 10 kilometres distance in three separate championships in 2017-2018: the European Championships, the Winter Olympics and the World Championships. Your friend expects that speed skaters will perform best at the Olympic games, so there she expects the fastest times. So you decide to test the null-hypothesis that average times are the same at the three occasions. In Figure \ref{fig:nonparmixed_1} we see a box plot of the data.

% H_0: $\mu_{EC}=\mu_{WC}_\mu{WO}$


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in rep(seq(1:12), 3) \%>\% as.factor(): could not find function "{}\%>\%"{}}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in rep(c("{}EuropeanChampionships"{}, "{}WorldChampionships"{}, "{}Olympics"{}), : could not find function "{}\%>\%"{}}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in rnorm(36, log(1017), 0.002) \%>\% exp() \%>\% round(2): could not find function "{}\%>\%"{}}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in time + rep(c(-0.2, 1, 0.2), each = 12): non-numeric argument to binary operator}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in max(time): invalid 'type' (closure) of argument}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in min(time): invalid 'type' (closure) of argument}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in data.frame(athlete, occasion, time) \%>\% dplyr::arrange(athlete): could not find function "{}\%>\%"{}}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in datalong \%>\% tidyr::spread(occasion, time) \%>\% dplyr::arrange(athlete): could not find function "{}\%>\%"{}}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in do.call(paste("{}writeForeign"{}, package, sep = "{}"{}), c(list(df = df, : object 'datalong' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in datalong \%>\% ggplot(aes(x = occasion, y = time)): could not find function "{}\%>\%"{}}}\end{kframe}
\end{knitrout}

In order to test this null-hypothesis, we run a linear mixed model with dependent variable time, and independent variable occasion. We use random effects for the differences in speed across skaters. In Figure \ref{fig:nonparmixed_2} we see the residuals. From this plot we clearly see that the assumption of equal variance (homogeneity of variance) is violated: the variance of the residuals in the Worldchampionships condition is clearly smaller than the variance of the European championships condition. From the histogram of the residuals in Figure \ref{fig:nonparmixed_3} we also see that the distribution of the residuals is not bell-shaped: it is positively skewed (skewed to the right).

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in datalong \%>\% lmer(time \textasciitilde{} occasion + (1 | athlete), data = .) \%>\% : could not find function "{}\%>\%"{}}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in cbind(datalong, res): object 'datalong' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in datalong \%>\% ggplot(aes(x = occasion, y = res)): could not find function "{}\%>\%"{}}}\end{kframe}
\end{knitrout}






\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in datalong \%>\% ggplot(aes(x = res)): could not find function "{}\%>\%"{}}}\end{kframe}
\end{knitrout}
% \\
% \\
Since the assumptions of homogeneity of variance and of normally distributed residuals are violated\footnote{Remember that assumptions relate to the population not samples: often-times your data set is too small to say anything about assumptions at the population level. Residuals for a data set of 8 persons might show very non-normal residuals, or very different variances for two subgroups of 4 persons each, but that might just be a coincidence, a random result because of the small sample size. If in doubt, it is best to use non-parametric methods.}, the results from the linear mixed model cannot be trusted. In order to answer our research question, we therefore have to resort to another kind of test. Here we discuss Friedman's test, a non-parametric test, for testing the null-hypothesis that the \textit{medians} of the three groups of data are the same (see Chapter \ref{chap:intro}. This Friedman test can be used in all situations where you have at least 2 levels of the within variable. In other words, you can use this test when you have data from three occasions, but also when you have data from 10 occasions or only 2. In a later section the Wilcoxon signed ranks test is discussed. This test is often used in social and behavioural sciences. The downside of this test is that it can only handle data sets with 2 levels of the within variable. In other words, it can only be used when we have data from two occasions. Friedman's test is therefore more generally applicable than Wilcoxon's. We therefore advise to always go with the Friedman test, but for the sake of completeness, we will also explain the Wilcoxon test.





\section{Friedman's test for $k$ measures}


Similar to many other non-parametric tests for testing the equality of medians, Friedman's test is based on ranks. Table \ref{tab:nonparmixed_4} shows the speed skating data in wide format.


\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in datawide \%>\% xtable(caption = "{}The speed skating data in wide format."{}, : could not find function "{}\%>\%"{}}}\end{kframe}

We rank all of these time measures by determining the fastest time, then the next to fastest time, etcetera, until the slowest time. But because the data in each row belong together (we compare individuals with themselves), we do the ranking \textit{row-wise}. For each athlete separately, we determine the fastest time (1), the next fastest time (2), and the slowest time (3) and put the ranks in a new table, see Table \ref{tab:nonparmixed_5}. There we see for example that athlete 1 had the fastest time at the European Championships (14.35, rank 1) and the slowest at the Olympics (16.42, rank 3).


\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in apply(datawide[, 2:4], 1, function(x) rank(x)): object 'datawide' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in eval(expr, envir, enclos): object 'datawide' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in t(ranks): object 'ranks' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in datawideranks \%>\% xtable(caption = "{}Row-wise ranks of the speed skating data."{}, : could not find function "{}\%>\%"{}}}\end{kframe}



















